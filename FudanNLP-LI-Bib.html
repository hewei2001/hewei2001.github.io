<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/logo.jpg"><link rel="icon" href="/img/logo.jpg"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#01213a"><meta name="author" content="Wei He"><meta name="keywords" content="Computer Science and Technology, Machine Learning, Deep Learning, Computer Vision, Natural Language Processing"><meta name="baidu-site-verification" content="code-J3wrn8WJYJ"><meta name="google-site-verification" content="0p_KJKTfB8EcahVDp0vYRjVRhHFw1SBWHi15OakKHY0"><meta name="description" content="本文分类索引复旦 NLP-LI 课题组的近期论文，课题组负责人为张奇教授、桂韬研究员。主要领域包括：NLP 高效性、NLP 可靠性、信息抽取、文本生成等。"><meta property="og:type" content="article"><meta property="og:title" content="复旦 NLP-LI 课题组近期论文索引"><meta property="og:url" content="https://hwcoder.top/FudanNLP-LI-Bib"><meta property="og:site_name" content="Hwcoder - Life Oriented Programming"><meta property="og:description" content="本文分类索引复旦 NLP-LI 课题组的近期论文，课题组负责人为张奇教授、桂韬研究员。主要领域包括：NLP 高效性、NLP 可靠性、信息抽取、文本生成等。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hwcoder.top/img/home/Fudan.jpg"><meta property="article:published_time" content="2022-10-05T14:34:58.000Z"><meta property="article:modified_time" content="2022-12-06T14:42:58.000Z"><meta property="article:author" content="Wei He"><meta property="article:tag" content="NLP"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://hwcoder.top/img/home/Fudan.jpg"><title>复旦 NLP-LI 课题组近期论文索引 | Hwcoder - Life Oriented Programming</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/mac.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var dntVal,CONFIG={hostname:"hwcoder.top",root:"/",version:"1.9.0",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h2, h3",placement:"left",visible:"always",icon:"§"},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4",collapseDepth:3},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"XGNf4GEnaFLiUijMUvz8HSBF-gzGzoHsz",app_key:"JPeVLcug6EcWdBTpGrDJSdKi",server_url:"https://xgnf4gen.lc-cn-n1-shared.com",path:"window.location.pathname",ignore_local:!0}},search_path:"/local-search.xml"};CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.4.2"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Hwcoder</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/bg/other.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="复旦 NLP-LI 课题组近期论文索引"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-10-05 22:34" pubdate>2022年10月5日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 11k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 61 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="科研札记" id="heading-76a81afdbe691e602875f061c03de9f1" role="tab" data-toggle="collapse" href="#collapse-76a81afdbe691e602875f061c03de9f1" aria-expanded="true">科研札记 <span class="list-group-count">(3)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-76a81afdbe691e602875f061c03de9f1" role="tabpanel" aria-labelledby="heading-76a81afdbe691e602875f061c03de9f1"><div class="category-post-list"><a href="/Read-Paper" title="How to Read a Paper ?" class="list-group-item list-group-item-action"><span class="category-post">How to Read a Paper ?</span> </a><a href="/Awesome-Sites" title="科研常用网站合集" class="list-group-item list-group-item-action"><span class="category-post">科研常用网站合集</span></a></div><div class="category-sub row nomargin-x"><a class="category-subitem list-group-item category-item-action col-10 col-md-11 col-xm-11" title="自然语言处理" id="heading-f48c43f5fd14bfd8a5057a0131e7aa20" role="tab" data-toggle="collapse" href="#collapse-f48c43f5fd14bfd8a5057a0131e7aa20" aria-expanded="true">自然语言处理 <span class="list-group-count">(1)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-f48c43f5fd14bfd8a5057a0131e7aa20" role="tabpanel" aria-labelledby="heading-f48c43f5fd14bfd8a5057a0131e7aa20"><div class="category-post-list"><a href="/FudanNLP-LI-Bib" title="复旦 NLP-LI 课题组近期论文索引" class="list-group-item list-group-item-action active"><span class="category-post">复旦 NLP-LI 课题组近期论文索引</span></a></div></div></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">复旦 NLP-LI 课题组近期论文索引</h1><p class="note note-info">本文最后更新于：2022年12月6日 晚上</p><div class="markdown-body"><p>本文分类索引 <a target="_blank" rel="noopener" href="https://nlp.fudan.edu.cn/">FudanNLP</a> 复旦大学自然语言处理课题组 <a target="_blank" rel="noopener" href="http://qizhang.info/">张奇</a> 老师和 <a target="_blank" rel="noopener" href="https://guitaowufeng.github.io/">桂韬</a> 老师的近期论文，通过梳理来尝试找出自己的研究兴趣。由于基础知识储备不足，恐挂一漏万，本文仅供个人娱乐。</p><h2 id="高效性-Efficient-NLP"><a href="#高效性-Efficient-NLP" class="headerlink" title="高效性 | Efficient NLP"></a>高效性 | Efficient NLP</h2><h3 id="插件微调-Plug-and-play"><a href="#插件微调-Plug-and-play" class="headerlink" title="插件微调 | Plug-and-play"></a>插件微调 | Plug-and-play</h3><ul><li>Making <strong>Parameter-efficient Tuning</strong> More Efficient: A Unified Framework for Classification Tasks<ul><li>Coling 2022 长文 Oral，周鑫，马若恬，邹易澄，陈炫婷，谢睿，武威，桂韬，张奇，黄萱菁</li><li>动机：PLM 的高效调参（只更新少量任务特有参数）的做法忽略了由<strong>任务特有的输出层</strong>（不同任务不同分类器）引起的参数低效问题。</li><li>模型：插件微调（plugin-tuning），将不同分类任务的标签空间映射到同一个词表空间（<strong>同义替换</strong>），从而使用一个统一分类器，节省了参数量。</li></ul></li><li>PlugAT: A <strong>Plug and Play</strong> Module to Defend against Textual Adversarial Attack<ul><li>Coling 2022 长文，郑锐，包容，刘勤，桂韬，张奇，黄萱菁，谢睿，武威</li><li>动机：对抗训练有效提升模型的鲁棒性，但是需要<strong>更新所有参数</strong>，且<strong>从零开始</strong>训练。</li><li>PlugAT 模型：保持原始模型参数冻结，向模型输入和注意力层中<strong>注入可学习的参数</strong> + 基于<strong>遗忘约束机制</strong>的对抗训练方法（防止对原任务造成副作用，过滤掉损伤原始性能的不良对抗样本）。</li></ul></li><li>Plug-Tagger: A <strong>Pluggable</strong> Sequence Labeling Framework Using Language Models<ul><li>AAAI 2021 长文，周鑫，马若恬，桂韬，谈一丁，张奇，黄萱菁</li><li>动机：插件用于将预训练模型快速部署到不同任务上，目前的<strong>前缀插件</strong>在不同的<strong>文本生成</strong>任务上表现很好，但是在序列标注这个<strong>分类任务</strong>上却失效，原因是不同的数据集<strong>需要不同的标签，需要训练不同的分类器</strong>。</li><li>模型：将序列标注<strong>当成生成任务</strong>来做 + 用一个<strong>高频标签代替</strong>每个类别 + <strong>任务专有前缀</strong>插件</li></ul></li></ul><h3 id="提示学习-Prompt-Tuning"><a href="#提示学习-Prompt-Tuning" class="headerlink" title="提示学习 | Prompt Tuning"></a>提示学习 | Prompt Tuning</h3><ul><li><strong>Template-free</strong> Prompt Tuning for <strong>Few-shot NER</strong><ul><li>NAACL 2022 长文，马若恬，周鑫，桂韬，谈一丁，李林阳，张奇，黄萱菁</li><li>动机：Prompt 在<strong>句子级</strong> few-shot 任务上表现良好，精巧的模版设计和 label word 选择功不可没；但在 NER 等<strong>词级别</strong>任务上，构造模版的方式遍历所有位置是非常费时的。</li><li>EntLM 模型：去除模板构造步骤，但保留 PLMs 的<strong>词预测范式</strong>（在实体位置预测类别相关的 label word + 在非实体位置预测原词）+ <strong>自动化选取</strong>合适 label word + 利用 prompt 语言模型<strong>减少预训练和下游任务的隔阂</strong></li></ul></li></ul><h3 id="彩票网络-Lottery-Ticket"><a href="#彩票网络-Lottery-Ticket" class="headerlink" title="彩票网络 | Lottery Ticket"></a>彩票网络 | Lottery Ticket</h3><ul><li><strong>Efficient</strong> Adversarial Training with Robust Early-Bird Tickets<ul><li>EMNLP 2022 主会，奚志恒*，郑锐*，桂韬，张奇，黄萱菁</li><li>动机：对抗训练可以提升鲁棒性，但是需要通过<strong>投影梯度下降生成对抗样本</strong>，比传统的微调更昂贵。本文发现在对抗训练的<strong>早期阶段</strong>，（通常是0.15~0.3个epochs，<strong>远在参数收敛之前</strong>），鲁棒的网络连接模式就浮现了。</li><li>鲁棒早鸟彩票网络：在对抗训练<strong>早期阶段寻找</strong>具有<strong>结构化稀疏度</strong>的鲁棒彩票（彩票收敛指标，帮助尽早搜索到彩票）+ <strong>剩余时间内</strong>对鲁棒彩票进行微调</li></ul></li><li><strong>Robust Lottery Tickets</strong> for Pre-trained Language Models<ul><li>ACL 2022 长文，郑锐，包容，周钰皓，梁迪，王思睿，武威，桂韬，张奇，黄萱菁</li><li>动机：彩票网络（PLMs 中<strong>媲美原始网络性能的子网络</strong>）在遭受<strong>对抗攻击</strong>时，表现出了比原始网络更差的鲁棒性。</li><li>模型：可学习权重掩码（识别<strong>鲁棒</strong>彩票网络），使用 concrete distribution 对掩码建模（解决二值掩码带来的离散优化问题）+ L0 范数平滑近似（促进掩码稀疏度）+ 对抗损失目标（确保准确性和鲁棒性）</li></ul></li></ul><h2 id="可靠性-Reliable-NLP"><a href="#可靠性-Reliable-NLP" class="headerlink" title="可靠性 | Reliable NLP"></a>可靠性 | Reliable NLP</h2><h3 id="数据集偏差-Bias"><a href="#数据集偏差-Bias" class="headerlink" title="数据集偏差 | Bias"></a>数据集偏差 | Bias</h3><ul><li><p>Kernel-Whitening: Overcome Dataset Bias with <strong>Isotropic Sentence Embedding</strong></p><ul><li>EMNLP 2022 主会，高颂杨，窦士涵，张奇，黄萱菁</li><li>动机：目前主流解决数据集偏差的方案是设计一个<strong>表层模型来预先识别有偏差</strong>的数据，但是<strong>两阶段</strong>方法增加了训练复杂度，在减轻偏见的同时导致了<strong>有效信息的衰减</strong>。</li><li>核白化：表示标准化（消除编码句子的特征之间的相关性，通过提供各向同性的数据分布来消除偏见问题）</li></ul></li><li><p>Decorrelate Irrelevant, Purify Relevant: Overcome <strong>Textual Spurious Correlations</strong> from a Feature Perspective</p><ul><li>Coling 2022 长文 Oral，窦士涵，郑锐，伍婷，高颂杨，单俊杰，张奇，吴月明，黄萱菁</li><li>动机：NLU 模型往往依赖伪相关性（数据集偏差），导致分布外数据集性能差。现有的去偏方法大多用<strong>有偏的特征</strong>来识别并尽可能忽略这些<strong>有偏样本</strong>，然而却阻碍了模型从这些样本的<strong>非偏部分</strong>学习。</li><li>模型：随机傅里叶特征和加权重采样（去除特征之间的依赖关系，减轻伪相关性）+ 互信息提纯特征（学习与任务更相关的特征）。</li></ul></li><li>Less is Better: Recovering Intended-<strong>Feature Subspace</strong> to <strong>Robustify NLU</strong> Models<ul><li>Coling 2022 长文，伍婷，桂韬</li><li>动机：现有的数据集去偏方法过度依赖于已知的偏差类型及属性（<strong>有监督</strong>），而不能捕获潜在的未知偏差。</li><li>RISK 模型：不直接去除偏差导致的 shortcuts（将其视为<strong>冗余特征</strong>输入）+ 将高维特征空间转换至<strong>低维流形</strong>上（使用一个 AutoEncoder 得到一个<strong>只包含有用特征</strong>的子空间）</li></ul></li><li>TextFlint: <strong>Unified</strong> Multilingual <strong>Robustness Evaluation Toolkit</strong> for Natural Language Processing<ul><li>ACL-IJCNLP 2021 System Demo，王枭，刘勤，桂韬，张奇</li><li>文本试金石（多语言鲁棒性检测工具）：用于<strong>数据集增强</strong>，包含多种文本转换、对抗样本生成、人群样本生成等，同时生成分析报告。在<strong>该工具生成的数据集上训练模型</strong>可以增强鲁棒性。</li></ul></li></ul><h3 id="对抗鲁棒性-Robustness"><a href="#对抗鲁棒性-Robustness" class="headerlink" title="对抗鲁棒性 | Robustness"></a>对抗鲁棒性 | Robustness</h3><ul><li>Flooding-X: Improving BERT’s <strong>Resistance to Adversarial Attacks</strong> via Loss-Restricted Fine-Tuning<ul><li>ACL 2022 长文，刘勤，郑锐，包容，刘婧漪，刘志华，程战战，乔梁，桂韬，张奇，黄萱菁</li><li>动机：对抗学习增强鲁棒性的方法是<strong>为每个输入样本</strong>生成对抗扰动，复杂性随着对抗样本所需要的<strong>梯度计算次数</strong>成倍上升</li><li>Flooding 模型：一种低成本的防御方法，但是依赖于<strong>参数的选择</strong></li><li>Flooding-X 模型：<strong>不需要生成额外的对抗扰动</strong>来训练模型，其时间消耗近似于模型微调</li></ul></li><li>Searching for an Effective Defender: Benchmarking <strong>Defense</strong> against <strong>Adversarial Word Substitution</strong><ul><li>EMNLP 2021，Zongyi Li，徐健涵，Jiehang Zeng，李林阳，郑骁庆，张奇</li><li>动机：NLP 任务中今进行<strong>词替换</strong>是常见的<strong>对抗攻击</strong>方法，但是现有方法缺少一个在相同条件的<strong>横向对比</strong>。</li><li>FreeLB++ 模型：在已有的 FreeLB 模型上改动，用 L2 范数扩大搜索范围，找到<strong>最易受攻击影响</strong>的点</li></ul></li></ul><h3 id="隐私保护-Privacy"><a href="#隐私保护-Privacy" class="headerlink" title="隐私保护 | Privacy"></a>隐私保护 | Privacy</h3><ul><li>TextFusion: <strong>Privacy-Preserving</strong> Pre-trained Model Inference via <strong>Token Fusion</strong><ul><li>EMNLP 2022 主会，周鑫，陆劲竹，桂韬，马若恬，费子楚，王宇然，丁勇， 张轶博，张奇，黄萱菁</li><li>动机：预训练云服务允许缺乏计算资源的用户将数据上传到云端完成推理，但纯文本可能包含私人信息，因此用户更愿意<strong>在本地进行部分计算得到中间表示</strong>后上传，但研究表明，<strong>中间表示也容易被还原为纯文本</strong>。</li><li>TextFusion：融合预测器（将多个可能含有隐私的词表示<strong>动态地融合为一个难以识别的词表示</strong>）+ 误导性的训练方案（用词向量空间中相近的词替换，使这些表示进一步被干扰）</li></ul></li></ul><h2 id="信息抽取-Information-Extraction"><a href="#信息抽取-Information-Extraction" class="headerlink" title="信息抽取 | Information Extraction"></a>信息抽取 | Information Extraction</h2><h3 id="事件抽取-Event-Argument-Extraction"><a href="#事件抽取-Event-Argument-Extraction" class="headerlink" title="事件抽取 | Event Argument Extraction"></a>事件抽取 | Event Argument Extraction</h3><ul><li>A Multi-Format <strong>Transfer Learning</strong> Model for Event Argument Extraction via Variational Information Bottleneck<ul><li>Coling 2022 长文 Oral，周杰，张奇，陈琴，贺梁，黄萱菁</li><li>动机：事件抽取往往需要<strong>对特定数据集设计特定事件框架</strong>，但这些框架难以迁移到新场景中。而新场景的重新标注往往太过复杂。</li><li>EAE 模型：共享-特定的提示框架（从包含不同形式的数据集学习<strong>形式特定和形式共享</strong>的知识）+ 变分信息瓶颈（保留共享的知识，<strong>遗忘无关的知识</strong>）</li></ul></li></ul><h3 id="论辩学习-Argument"><a href="#论辩学习-Argument" class="headerlink" title="论辩学习 | Argument"></a>论辩学习 | Argument</h3><ul><li>A <strong>Structure-Aware</strong> Argument Encoder for <strong>Literature Discourse</strong> Analysis<ul><li>Coling 2022 短文，李寅子，陈伟，魏忠钰，黄煜俊，王楚珺，王思远，张奇，黄萱菁，吴力波</li><li>动机：论点表示学习倾向于<strong>平等对待</strong>句子中的词元（token），而忽略了形成<strong>论辩语境的隐含结构</strong>；特别是在科学文献中含有大量术语没有得到关注。</li><li>模型：将 token 分为框架词和主题词 + <strong>论点注意力机制</strong>建模（对 token 间的交互建模<strong>结构信息</strong>）+ 考虑段落级的位置信息来学习论点的高级结构。</li></ul></li><li><strong>Discrete</strong> Argument Representation Learning for Interactive <strong>Argument Pair Identification</strong><ul><li>NAACL-HLT 2021，Lu Ji，魏忠钰，Jing Li，张奇，黄萱菁</li><li>动机：在双方辩论的过程中，通常会对一个主题进行<strong>不同角度的阐述</strong>，本文旨在找出同一角度的<strong>论辩对</strong>。</li><li>模型：获取论辩语言的<strong>离散</strong>表征 + 层级结构建模（融合<strong>上下文</strong>知识）</li></ul></li></ul><h3 id="命名实体识别-NER"><a href="#命名实体识别-NER" class="headerlink" title="命名实体识别 | NER"></a>命名实体识别 | NER</h3><ul><li>MINER: Improving <strong>Out-of-Vocabulary</strong> Named Entity Recognition from an Information Theoretic Perspective<ul><li>ACL 2022 长文，王枭，窦士涵，熊立茂，邹易澄，张奇，桂韬，乔梁，程战战，黄萱菁</li><li>动机：过去的 NER 方法过度依赖实体词本身的信息，以至于对 <strong>OOV</strong> 的识别很差，现实中的实体词往往呈<strong>长尾分布</strong>，意味着效果不好。</li><li>模型：基于互信息的训练目标（泛化信息最大化 + 多余信息最小化），强化上下文，防止过度关注实体本身。</li></ul></li><li>Searching for Optimal <strong>Subword</strong> Tokenization in <strong>Cross-domain NER</strong><ul><li>IJCAI 2022 长文，马若恬，谈一丁，周鑫，陈炫婷，桂韬，张奇</li><li>动机：无监督领域适应（UDA）任务常通过<strong>域无关表示学习</strong>完成，但对于 NER 这种<strong>词级别</strong>的任务，更需要对<strong>实体词进行迁移和对齐</strong>，应该把<strong>域无关表征放到 subword 上</strong>。</li><li>X-Piece 模型：将实体词重新 tokenize 成 subword，使<strong>源域和目标域尽量靠近</strong>，当成最优化问题解决。</li></ul></li></ul><h3 id="序列标注-Sequence-Labeling"><a href="#序列标注-Sequence-Labeling" class="headerlink" title="序列标注 | Sequence Labeling"></a>序列标注 | Sequence Labeling</h3><ul><li><strong>Uncertainty-Aware</strong> Sequence Labeling<ul><li>TASLP 2022，叶佳成，周翔，郑骁庆，桂韬，张奇</li><li>动机：CRF 用于序列标注无法同时建模<strong>局部和全局依赖</strong>。</li><li>两阶段框架：先生成 draft 标签，再使用<strong>双流自注意力模型</strong>修改（基于长距离标签依赖） + <strong>贝叶斯网络</strong>查找可能出错的 draft（减少错误 draft 的边际效应）</li></ul></li><li><strong>Larger-Context</strong> Tagging: When and Why Does It Work?<ul><li>NAACL 2021，Jinlan Fu，Liangjing Feng，张奇，黄萱菁</li><li>动机：<strong>句子级序列标注</strong>任务十分热门，但很少人关注更多的上下文信息是否有用，例如<strong>文档级序列标注</strong>。本文在多个任务和数据集上进行了验证，并提出了一种<strong>属性辅助评估方法</strong>。</li></ul></li></ul><h3 id="社交媒体-Social-Media"><a href="#社交媒体-Social-Media" class="headerlink" title="社交媒体 | Social Media"></a>社交媒体 | Social Media</h3><ul><li>A Progressive Framework for Role-Aware <strong>Rumor</strong> Resolution<ul><li>Coling 2022 长文，陈蕾，李冠颖，魏忠钰，杨洋，周葆华，张奇，黄萱菁</li><li>新任务：引爆点识别，识别出在对谣言传播具有推动作用或对谣言判别有指示作用的消息。</li><li>模型：非对称的图循环神经网络（建模信息传播树）+ 渐进式预测（引爆点识别、角色感知、谣言判别）</li></ul></li></ul><h3 id="关键短语生成-Keyphrase-Generation"><a href="#关键短语生成-Keyphrase-Generation" class="headerlink" title="关键短语生成 | Keyphrase Generation"></a>关键短语生成 | Keyphrase Generation</h3><ul><li>Searching Effective Transformer for <strong>Seq2Seq Keyphrase Generation</strong><ul><li>NLPCC 2021 长文，Yige Xu，Yichao Luo，邹易澄，Zhengyan Li，张奇，邱锡鹏，黄萱菁</li><li>动机：Transformer 在 KG 任务上表现不如传统的 RNN 模型，本文探究其原因并提出「<strong>信息稀疏假说</strong>」，设计实验并验证其正确性。主要原因是 KG 任务中<strong>关键信息过于稀疏</strong>，而原始的 Transformer 由于全连接注意力，容易<strong>过度关注</strong> local context。</li><li>模型：限制自注意力机制 + 引入导向信息。</li></ul></li><li>Keyphrase Generation with <strong>Fine-Grained Evaluation</strong>-Guided <strong>Reinforcement Learning</strong><ul><li>EMNLP 2021 长文 Finding，Yichao Luo，Yige Xu，叶佳成，邱锡鹏，张奇</li><li>动机：过去的 KG 评价指标通常采用 F1 得分进行<strong>短语级的精确匹配</strong>，但忽略了<strong>语义上可能正确</strong>的答案。</li><li>模型：<strong>细粒度评价指标</strong>（词级 F1、编辑距离等）+ 原始的短语级 F1 <strong>共同作为</strong> RL 的 reward</li></ul></li><li><p>One2Set: Generating <strong>Diverse Keyphrases as a Set</strong></p><ul><li>ACL-IJCNLP 2021 长文，叶佳成，桂韬，Yichao Luo，Yige Xu，张奇</li><li>动机：现有的 Seq2seq 模型会将关键短语<strong>拼接成序列</strong>作为目标序列训练，但却忽略了关键短语本身是<strong>无序的</strong>。</li><li>One2Set 模型：一组可学习控制编码（生成<strong>并行、无序的</strong>关键短语）+ K 步目标指派（双向匹配预测值与目标值，减少预测结果中的<strong>重复值</strong>，增加多样性）</li></ul></li><li><p><strong>Heterogeneous Graph Neural Networks</strong> for Keyphrase Generation</p><ul><li>EMNLP 2021 长文，叶佳成，Ruijian Cai，桂韬，张奇</li><li>动机：KG 任务需要预测文档中<strong>出现的或未出现的</strong>关键短语，而对于<strong>未出现词</strong>往往生成的不可控、不准确。</li><li>模型：先检索和源文档<strong>相似的文档-短语对</strong>，放入<strong>多级图模型</strong>抽取<strong>不同粒度</strong>的关系，解码器使用<strong>多级注意力</strong> + <strong>拷贝机制</strong>（直接拷贝相似文档中合适的答案）</li></ul></li></ul><h3 id="实体关系抽取-Relation-Extraction"><a href="#实体关系抽取-Relation-Extraction" class="headerlink" title="实体关系抽取 | Relation Extraction"></a>实体关系抽取 | Relation Extraction</h3><ul><li><p>A Relation-Oriented Clustering Method for <strong>Open Relation Extraction</strong></p><ul><li>EMNLP 2021 长文，赵君，桂韬，张奇，周雅倩</li><li>动机：基于聚类的无监督方法成为开放域关系抽取的重要方法，但是向量空间中的距离并不能完全代表关系语义相似性（对齐），会导致关系分类错误。</li><li>RoCORE：将实例的向量表示聚集到关系质心，最小化具有相同关系的实例之间的距离。</li></ul></li><li><p>SENT: <strong>Sentence-level Distant</strong> Relation Extraction via <strong>Negative Training</strong></p><ul><li>ACL-IJCNLP 2021 长文，马若恬，桂韬，李林阳，张奇，黄萱菁，周雅倩</li><li>动机：实体关系抽取通常采用 bag labels 形式，即对<strong>匹配的 sentence bag</strong> 在<strong>标签池</strong>中选择标签，但是会引入很多噪声（<strong>多标签噪声、没有正确标签噪声</strong>）。</li><li>Negative Training：用互补标签表示「<strong>该对象不属于此类标签</strong>」来降低噪声。</li><li>SENT 框架：对噪声数据进行互补标签构建，并将其转化为可利用的数据。</li></ul></li></ul><h2 id="文本生成-Text-Generation"><a href="#文本生成-Text-Generation" class="headerlink" title="文本生成 | Text Generation"></a>文本生成 | Text Generation</h2><h3 id="多跳问答-Multi-hop-QA"><a href="#多跳问答-Multi-hop-QA" class="headerlink" title="多跳问答 | Multi-hop QA"></a>多跳问答 | Multi-hop QA</h3><ul><li>Locate Then Ask: Interpretable <strong>Stepwise</strong> Reasoning for <strong>Multi-hop Question Answering</strong><ul><li>Coling 2022 长文，王思远，魏忠钰，范智昊，张奇，黄萱菁</li><li>动机：多跳推理需要聚合多个文档来回答复杂问题，过去通常将其分别为多个单跳问题来解答，但是每个单跳推理步骤缺乏支持事实，可能导致<strong>不可解释的错误分解</strong>。</li><li>模型：每个中间步骤 = 单跳支持句识别 + 单跳问题生成，采用<strong>统一阅读器模型</strong>进行中间跳推理和最终跳推理。</li></ul></li><li>CQG: A Simple and Effective Controlled Generation Framework for <strong>Multi-hop Question Generation</strong><ul><li>ACL 2022 长文，费子楚，张奇，桂韬，梁迪，王思睿，武威，黄萱菁</li><li>动机：现有的生成模型已经能够生成与答案相对应的正确问题，但无法保证<strong>生成问题的复杂性</strong>（浅层问题）。</li><li>CQG 模型：多跳推理链中关键实体的多跳问题 + 基于 Transformer 的可控解码器</li></ul></li><li><strong>Iterative GNN-based Decoder</strong> for Question Generation<ul><li>EMNLP 2021，费子楚，张奇，周雅倩</li><li>动机：QG 任务旨在从一个文档中生成问答对，过去的解码器忽略了<strong>先前生成文本</strong>中的<strong>结构信息</strong>，且忽略了文本中<strong>重复出现的词</strong>的影响。因此，要将前面生成的词在后续生成中<strong>充当辅助信息</strong>才行。</li><li>IGND：每一个解码步骤都使用图神经网络（更能<strong>捕获段落中的依赖关系</strong>）对先前的文本建模</li></ul></li></ul><h3 id="数学问题-Math-Word-Problem"><a href="#数学问题-Math-Word-Problem" class="headerlink" title="数学问题 | Math Word Problem"></a>数学问题 | Math Word Problem</h3><ul><li>Automatic Math Word Problem <strong>Generation</strong> With Topic-Expression <strong>Co-Attention</strong> Mechanism and <strong>Reinforcement Learning</strong><ul><li>TASLP 2022，Qinzhuo Wu，张奇，黄萱菁</li><li>动机：给定主题和表达式生成对应的可解数学问题，常规的生成方法容易导致<strong>主题无关或者问题不可解</strong>。</li><li>MWPGen 模型：<strong>主题-表达式</strong>注意力机制（抽取二者的相关信息）+ <strong>强化学习</strong>（以问题的标答为 reward）</li></ul></li><li><p>An Edge-Enhanced <strong>Hierarchical</strong> <strong>Graph-to-Tree</strong> Network for Math Word Problem Solving</p><ul><li>EMNLP 2021，Qinzhuo Wu，张奇，魏忠钰</li><li>动机：利用图神经网络解决数学问题是，可能没有考虑到<strong>图中的边缘标签信息</strong>和跨句子的<strong>远程词</strong>关系，只关注和当前词最相关的区域。</li><li>EEH-G2T：句子级聚合（边缘增强，聚合边缘标签信息）+ 问题级聚合（学习远程词）+ 树结构（注意到问题的不同部分）</li></ul></li><li><p>Math Word Problem <strong>Solving</strong> with Explicit <strong>Numerical Values</strong></p><ul><li>ACL-IJCNLP 2021，Qinzhuo Wu，张奇，魏忠钰，黄萱菁</li><li>动机：现有的数学问题解决模型，都只将<strong>数值看作数字符号</strong>，而有时候数值类型也会<strong>决定表达式</strong>。</li><li>NumS2T 模型：用<strong>序列到树模型</strong>表示数值 + 数值属性预测机制（预测<strong>数值类型</strong>及其<strong>在表达式中的地位</strong>）</li></ul></li><li>A Knowledge-Aware Sequence-to-Tree Network for Math Word Problem Solving<ul><li>EMNLP 2020，Qinzhuo Wu，张奇，Jinlan Fu，黄萱菁</li></ul></li></ul><h3 id="对话系统-Dialogue-Systems"><a href="#对话系统-Dialogue-Systems" class="headerlink" title="对话系统 | Dialogue Systems"></a>对话系统 | Dialogue Systems</h3><ul><li>Thinking Clearly, Talking Fast: <strong>Concept-Guided</strong> <strong>Non-Autoregressive Generation</strong> for Open-Domain Dialogue Systems<ul><li>EMNLP 2021 长文，邹易澄，刘志华，胡星武，张奇</li><li>动机：现有的 seq2seq 对话系统难以掌握<strong>同类概念迁移</strong>，且无法在回答中引入<strong>多个关联的概念</strong>。</li><li>CG-nAR 模型：多概念决策模块（从<strong>概念图</strong>模型中找出相关概念）+ <strong>插入式 Transformer</strong>（插入一个概念后非自回归地<strong>补全</strong>回答）</li></ul></li><li><strong>Topic-Oriented</strong> Spoken Dialogue Summarization for Customer Service with <strong>Saliency-Aware</strong> Topic Modeling<ul><li>AAAI 2021 长文，邹易澄，Minlong Peng，张奇，黄萱菁</li><li>动机：对话摘要任务中，大量<strong>噪声和共同语义</strong>导致潜在信息难以发掘，普通的<strong>主题模型</strong>难以应用。在客服对话中，还需要根据顾客特定信息进行回复。</li><li>模型：<strong>两阶段</strong>对话摘要（TDS）+ <strong>显著性感知</strong>神经主题模型（SAMT，减少无关噪声的影响）</li></ul></li><li><strong>Unsupervised Summarization</strong> for <strong>Chat Logs</strong> with Topic-Oriented Ranking and <strong>Context-Aware</strong> Auto-Encoders<ul><li>AAAI 2021 长文，邹易澄，张奇，黄萱菁</li><li>动机：不同于传统文本摘要，聊天记录中含有<strong>碎片化、递进的主题</strong>，和大量<strong>晦涩难懂的句子</strong>。</li><li>RankAE 模型：面向主题的排序策略（筛选具有<strong>中心性和多样性</strong>的主题言论）+ 去噪自编码器（根据选中的言论生成摘要）</li></ul></li><li><strong>Low-Resource Dialogue Summarization</strong> with <strong>Domain-Agnostic Multi-Source</strong> Pretraining<ul><li>EMNLP 2021 长文，邹易澄，朱柏霖，胡星武，桂韬，张奇</li><li>动机：对话摘要的标注数据过少，现有的<strong>低资源</strong>方法都在<strong>其他领域预训练模型后微调</strong>，但他们都忽略了对话和传统问答的区别。</li><li>模型：多资源对抗学习（<strong>域不可知</strong>的摘要能力）+ 用大规模领域内数据<strong>分别训练</strong>对话<strong>编码器</strong>和摘要<strong>解码器</strong></li></ul></li></ul><h3 id="知识图谱答案生成-KG"><a href="#知识图谱答案生成-KG" class="headerlink" title="知识图谱答案生成 | KG"></a>知识图谱答案生成 | KG</h3><ul><li>LFKQG: A Controlled Generation Framework with Local Fine-tuning for <strong>Question Generation</strong> over <strong>Knowledge Bases</strong><ul><li>Coling 2022 长文，费子楚，周鑫，张奇，桂韬，黄萱菁</li><li>动机：KBQG 基于知识图谱子图中的<strong>指定答案实体</strong>生成问题，但只关注与答案实体最相关的部分，忽略了其他部分；且 KBQG 无法处理 OOV 谓词。</li><li>LFKQG 模型：受控生成方法（确保问题和整个子图相关）+ 局部微调（利用 PLM 适应 OOV 的能力）</li></ul></li></ul><h3 id="证明生成-Proof-Generation"><a href="#证明生成-Proof-Generation" class="headerlink" title="证明生成 | Proof Generation"></a>证明生成 | Proof Generation</h3><ul><li>ProofInfer: Generating Proof via <strong>Iterative Hierarchical Inference</strong><ul><li>EMNLP 2022 主会，费子楚，张奇，周鑫，桂韬，黄萱菁</li><li>任务描述：给定一系列自然语言表达的 Facts 和 Rules，构建证明树证明 Hypothesis。</li><li>动机：过去的模型采用逐步将<strong>单个节点链接到结论</strong>，生成几个证明路径再合并，而不是整个树。</li><li>ProofInfer：迭代层次推理生成整个树（每一步生成一层 + 采用<strong>文本到文本范式来预测一层</strong>的多个节点） + 分治（将证明树<strong>递归编码</strong>为纯文本，而不会丢失结构信息）</li></ul></li></ul><h2 id="文本匹配-Text-Matching"><a href="#文本匹配-Text-Matching" class="headerlink" title="文本匹配 | Text Matching"></a>文本匹配 | Text Matching</h2><h3 id="文本语义匹配-Text-Semantic-Matching"><a href="#文本语义匹配-Text-Semantic-Matching" class="headerlink" title="文本语义匹配 | Text Semantic Matching"></a>文本语义匹配 | Text Semantic Matching</h3><ul><li>Divide and Conquer: Text <strong>Semantic Matching</strong> with Disentangled <strong>Keywords and Intents</strong><ul><li>ACL 2022 长文，邹易澄，刘宏伟，桂韬，王浚哲，张奇，唐萌，李海翔，Daniel Wang</li><li>动机：基于 PLMs 的文本匹配方法通过处理<strong>句子中的单词</strong>来进行文本内容匹配，但是待匹配的句子通常包含<strong>不同匹配粒度</strong>的内容：关键词（需要<strong>严格匹配</strong>的事实）+ 意图（可以通过<strong>多种表述</strong>传达）</li><li>DC-Match 策略：将关键词和意图分离（Mask 互补）分而治之，当关键词和意图均匹配才匹配句子。</li></ul></li></ul><h3 id="跨语言语义匹配-Cross-Linguistic"><a href="#跨语言语义匹配-Cross-Linguistic" class="headerlink" title="跨语言语义匹配 | Cross-Linguistic"></a>跨语言语义匹配 | Cross-Linguistic</h3><ul><li><strong>Cross-Linguistic Syntactic Difference</strong> in Multilingual BERT: How Good is It and How Does It Affect Transfer?<ul><li>EMNLP 2022 主会，徐凝雨，桂韬，马若恬，张奇，叶婧婷，张梦翰，黄萱菁</li><li>动机：多语言 BERT 拥有较强跨语言句法能力，在<strong>某些语言之间</strong>能够有效地进行句法知识的<strong>零样本跨语言</strong>迁移。</li><li>实验：对 24 种类型迥异的语言，研究了 mBERT 得到的<strong>依存句法关系表示的分布</strong>，证明了不同语言分布之间的距离与<strong>语言间的形式句法差异</strong>高度一致。因此，可以在零样本时根据<strong>不同语言的形态句法属性</strong>来选择最佳的迁移<strong>源语言</strong>。</li></ul></li></ul><h2 id="情感分析-Sentiment-Analysis"><a href="#情感分析-Sentiment-Analysis" class="headerlink" title="情感分析 | Sentiment Analysis"></a>情感分析 | Sentiment Analysis</h2><h3 id="隐式情感分析-Implicit"><a href="#隐式情感分析-Implicit" class="headerlink" title="隐式情感分析 | Implicit"></a>隐式情感分析 | Implicit</h3><ul><li><p><strong>Causal intervention</strong> improves <strong>implicit</strong> sentiment analysis</p><ul><li>Coling 2022 长文，王思尹，周杰，孙长志，叶俊杰，桂韬，张奇，黄萱菁</li><li>动机：现有的模型依赖<strong>伪相关性</strong>（只关注明确的情感词），导致隐式情感分析存在困难。</li><li>ISAIV 模型：引入<strong>工具变量</strong>来消除混杂因果效应（随机扰动句子）+ 两阶段训练</li></ul></li><li><p>Learning Implicit Sentiment in <strong>Aspect-based Sentiment Analysis</strong> with <strong>Supervised Contrastive Pre-Training</strong></p><ul><li>EMNLP 2021，Zhengyan Li，邹易澄，Chong Zhang，张奇，魏忠钰</li><li>动机：ABSA 中也具有隐式情感问题（意见词的表意不明显）。</li><li>SCAPT：将隐式情感词和具有相同情感的显式情感词对齐，进行预训练，使得模型可以捕捉隐式情感</li></ul></li></ul><h2 id="多模态-Multi-Model"><a href="#多模态-Multi-Model" class="headerlink" title="多模态 | Multi-Model"></a>多模态 | Multi-Model</h2><h3 id="文档实体识别-Doc-NER"><a href="#文档实体识别-Doc-NER" class="headerlink" title="文档实体识别 | Doc NER"></a>文档实体识别 | Doc NER</h3><ul><li>Read Extensively, Focus Smartly: A <strong>Cross-document</strong> Semantic Enhancement Method for Visual <strong>Documents NER</strong><ul><li>Coling 2022 长文 Oral，赵君，赵鑫，詹文煜，桂韬，张奇，乔梁，程战战，蒲世良</li><li>动机：过去的<strong>富视觉文档实体识别</strong>往往将注意力分配在文档内部的不相关区域，忽略了相关文档蕴含的信息。</li><li>模型：注意力掩码机制（减少当前文档不相关区域的关注）+ 跨文档感知（从相关文档收集信息辅助预测）。</li></ul></li></ul><h3 id="博客标签推荐-Hashtag-Rec"><a href="#博客标签推荐-Hashtag-Rec" class="headerlink" title="博客标签推荐 | Hashtag Rec"></a>博客标签推荐 | Hashtag Rec</h3><ul><li><strong>Co-Attention</strong> Memory Network for <strong>Multimodal</strong> Microblog’s Hashtag Recommendation<ul><li>TKDE 2021 长文，Renfeng Ma，邱锡鹏，张奇，Xiangkun Hu, Yu-Gang Jiang，黄萱菁</li><li>动机：标签推荐经常被视为<strong>多标签分类</strong>任务，但事实上用户总时在<strong>创造新标签</strong>，固定的标签集效果不好。</li><li>模型：将其视为<strong>匹配任务</strong>，互注意力机制（学习<strong>多模态</strong>博客内容，并从记录中抽取词汇作为标签）</li></ul></li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E7%A7%91%E7%A0%94%E6%9C%AD%E8%AE%B0/" class="category-chain-item">科研札记</a> <span>></span> <a href="/categories/%E7%A7%91%E7%A0%94%E6%9C%AD%E8%AE%B0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" class="category-chain-item">自然语言处理</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/NLP/">#NLP</a></div></div><div class="license-box my-3"><div class="license-title"><div>复旦 NLP-LI 课题组近期论文索引</div><div>https://hwcoder.top/FudanNLP-LI-Bib</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Wei He</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2022年10月5日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i> </span></a><a target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="NC - 非商业性使用"><i class="iconfont icon-nc"></i> </span></a><a target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="SA - 相同方式共享"><i class="iconfont icon-sa"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/PyTorch-Note-1" title="PyTorch笔记 #1 基础操作"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">PyTorch笔记 #1 基础操作</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/LeetCode-Tree" title="力扣刷题笔记 #13 树"><span class="hidden-mobile">力扣刷题笔记 #13 树</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.4.16/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"jdbBr3BddTiqSCPnXw6sXFv7-gzGzoHsz","appKey":"2bjgwDr2opjVCwhgjDMpk53c","path":"window.location.pathname","placeholder":"说点什么吧( •̀ ω •́ )✧","avatar":"retro","meta":["nick","mail","link"],"requiredFields":["nick"],"pageSize":10,"lang":"zh-CN","highlight":true,"recordIP":true,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t){var e=Fluid.plugins.typing,i=t.getElementById("subtitle");i&&e&&e(i.getAttribute("data-typed-text"))}((window,document))</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init({tocSelector:"#toc-body",contentSelector:".markdown-body",headingSelector:CONFIG.toc.headingSelector||"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:CONFIG.toc.collapseDepth||0,scrollSmooth:!0,headingsOffset:-t}),0<o.find(".toc-list-item").length&&o.css("visibility","visible"))})</script><script>!function(){var i,t=CONFIG.code_language.enable&&CONFIG.code_language.default,c=CONFIG.copy_btn;(t||c)&&(i="",i+='<div class="code-widget">',i+="LANG",i+="</div>",jQuery(".markdown-body pre").each(function(){var e,a,n=jQuery(this);0<n.find("code.mermaid").length||0<n.find("span.line").length||(e="",t&&(e=CONFIG.code_language.default,0<n[0].children.length&&2<=n[0].children[0].classList.length&&n.children().hasClass("hljs")?e=n[0].children[0].classList[1]:n[0].getAttribute("data-language")?e=n[0].getAttribute("data-language"):n.parent().hasClass("sourceCode")&&0<n[0].children.length&&2<=n[0].children[0].classList.length?(e=n[0].children[0].classList[1],n.parent().addClass("code-wrapper")):n.parent().hasClass("markdown-body")&&0===n[0].classList.length&&n.wrap('<div class="code-wrapper"></div>'),e=e.toUpperCase().replace("NONE",CONFIG.code_language.default)),n.append(i.replace("LANG",e).replace('code-widget">',(a=n[0],(0<=Fluid.utils.getBackgroundLightness(a)?"code-widget-light":"code-widget-dark")+(c?' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>':' code-widget">')))),c&&Fluid.utils.createScript("https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js",function(){new window.ClipboardJS(".copy-btn",{target:function(e){for(var a=e.parentNode.childNodes,n=0;n<a.length;n++)if("CODE"===a[n].tagName)return a[n]}}).on("success",function(e){e.clearSelection(),e.trigger.innerHTML=e.trigger.innerHTML.replace("icon-copy","icon-success"),setTimeout(function(){e.trigger.innerHTML=e.trigger.innerHTML.replace("icon-success","icon-copy")},2e3)})}))}))}()</script><script>Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>