<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>IR学习笔记 #3 向量空间模型</title>
    <link href="/2021/08/22/IR-Note-3/"/>
    <url>/2021/08/22/IR-Note-3/</url>
    
    <content type="html"><![CDATA[<p>回忆前两个模型，我们发现统计语言模型在布尔模型上，做出了最佳匹配和排序结果的改进。但是，仍然没有考虑到「<strong>词项的权重</strong>」。</p><p>在向量空间模型中，我们容易联想到用向量来表示文档和查询，再通过计算余弦来得到两个向量的距离，从而得到相似性度量。</p><p>那么，如何选取向量空间 basis vector (基向量)？如何将目标转化为向量？如何为各个维度选取 magnitide (幅值)，从而考虑权重？如何在高维空间计算向量距离？</p><h2 id="Vector-Space-Model-向量空间模型"><a href="#Vector-Space-Model-向量空间模型" class="headerlink" title="Vector Space Model | 向量空间模型"></a>Vector Space Model | 向量空间模型</h2><p>通常地，我们选择用 linearly independent (线性独立) 或 orthogonal (正交) 的基向量来张成<strong>向量空间</strong>，这样可以使得维度最少。那么，如何选取基向量？</p><p>这是一个特征选择问题，在 IR 中，通常有两种方式：</p><ol><li><p>Core concept (核心概念) 的思想：把词语的类型分类，按照其在不同分类上的「倾斜程度」决定向量的值，可以使维度尽量少。但是，由于语义上的多样性，很难实现。目前有 WordNet, HowNet, HNC 等模型。</p></li><li><p>把出现过的 term 都当作是一个基向量，并<strong>假设</strong>所有的基向量都是相互正交、相互独立的。这样将会得到一个维度不断增长的向量空间（随着词典表扩大）。</p></li></ol><p>以下我们采用第二种方式。一个 Doc 或 Query 的向量表示就是：所有出现在文档中的 term 的向量之和。</p><h3 id="Term-Weighting-词项权重"><a href="#Term-Weighting-词项权重" class="headerlink" title="Term Weighting | 词项权重"></a>Term Weighting | 词项权重</h3><p>当一个 term 在文档中不断出现时，在这个方向上的向量幅值就会很大。这样比起布尔模型的 0/1 二值，更能反映了这个 term 的重要性。这便是决定权重的 <em>tf</em> (<strong>term frequency</strong>，词项频率) 方法。</p><p>然而，原始的 <em>tf</em> 值会面临这样一个严重的问题：即在和查询进行相关度计算时，所有 term 都被认为是同等重要的。</p><p>实际上，某些 term 对于相关度计算来说几乎没有或很少有区分能力。一个很直接的想法就是给包含在较多文档中的词项赋予较低的权重。为此，引入变量 <em>df</em> (<strong>document frequency</strong>，文档集频率)，即有多少文档包含了该 term。df 值越大，说明该 term 越不重要。</p><p>为了计算的方便，将其标准化得到 <em>idf</em> (<strong>inverse document frequency</strong>，逆文档频率)：</p><script type="math/tex; mode=display">idf_t=\log \left( \frac{N}{df_t} \right)</script><p>观察该式发现，<em>idf</em> 虽然可以使得在较多文档中的词项权值降低，但与 <em>tf</em> 相反的是，这样做的缺点是：对那些极少出现的词极度敏感。</p><p>为此，我们将二者结合在一起，诞生了 <strong><em>tf·idf</em></strong> 方法——在文本处理领域中使用最广泛的数值权重计算方法。方法基于的思想和构造的统计量都很简单，但是在实际中却表现了很好的性能。</p><p>在 VSM 中，我们会将词项的 <em>tf·idf</em> 存储在词典表（词项-文档）矩阵中，作为向量的幅值，用于后续的计算。</p><h3 id="Similarity-相似度计算"><a href="#Similarity-相似度计算" class="headerlink" title="Similarity | 相似度计算"></a>Similarity | 相似度计算</h3><p>当我们已经把文档表示成 $R^{v}$ 上的向量，从而可以计算文档与文档之间的相似度（根据向量内积或者<strong>余弦夹角</strong>）。</p><p>设 <em>D~1~</em> 和 <em>D~2~</em> 表示 VSM 中的两个向量：</p><script type="math/tex; mode=display">\begin{aligned}&D_{1}=D_{1}\left(w_{11}, w_{12}, \ldots, w_{1 n}\right) \\&D_{2}=D_{2}\left(w_{21}, w_{22}, \ldots, w_{2 n}\right)\end{aligned}</script><p>可以借助于 N 维空间中两个向量之间的某种距离来表示文档之间的相似度，常用的方法是使用向量之间的內积来计算：</p><script type="math/tex; mode=display">\operatorname{Sim}\left(D_{1}, D_{2}\right)=\sum_{k=1}^{n} w_{1 k} \times w_{2 k}</script><p>考虑到向量的<strong>归一化</strong>，则可以使用两个向量的余弦值来表示相似系数：</p><script type="math/tex; mode=display">\operatorname{Sim}\left(D_{1}, D_{2}\right)=\cos \theta=\frac{\sum_{k=1}^{n} w_{1 k} \times w_{2 k}}{\sqrt{\sum_{k=1}^{n} w_{1 k}^{2} \sum_{k=1}^{n} w_{2 k}^{2}}}</script><p>要注意，这里使用向量内积，是基于对所有向量相互独立、相互正交的假设，否则计算内积也就失去了意义。对于相关的基向量，应该评估 Term 之间的相关度 <em>T~i,j~</em>，再把向量当成多项式计算，最后代入 <em>T~i,j~</em>。</p><p>此外，在其他的考虑权重的模型中，如 Lucene，在计算相似度时引入了更多的因子，如 <em>tf·idf</em>，<em>boost~t~</em>，<em>overlap(q,d)</em> 等，对应用情形、平滑度加以考量。</p><h3 id="VSM-实际应用"><a href="#VSM-实际应用" class="headerlink" title="VSM 实际应用"></a>VSM 实际应用</h3><p>在 IR 中应用 VSM 模型时，相似度在检索结果中有两种体现：</p><ol><li><strong>Threshold</strong> (阈值)：对于每个查询，只在相似度大于一定阈值的文档中检索，如 Sim &gt; 0.50 的文档中，减少查询范围。</li><li><strong>Ranking</strong>：对于每个查询，返回相似度排名 Top n 的文档，以相似度排序。</li></ol><p>而 VSM 模型也有着致命的<strong>缺点</strong>：</p><ul><li><p>对于大的文档集（10w+ term），向量维度太多导致难以存储和计算。</p></li><li><p>一篇文档的词数（1k+ term）远低于总的词数——高维稀疏矩阵。</p></li><li>词项之间的相关性，导致了大量冗余的基向量。</li></ul><h2 id="Latent-Semantic-Indexing-潜层语义索引"><a href="#Latent-Semantic-Indexing-潜层语义索引" class="headerlink" title="Latent Semantic Indexing | 潜层语义索引"></a>Latent Semantic Indexing | 潜层语义索引</h2><p>潜层语义索引，也被称为 LSA (Latent Semantic Analysis，潜在语义分析)，是针对向量空间的「<strong>高维稀疏</strong>」问题提出的解决方法，利用线性代数中的<strong>奇异值分解</strong>降低维度（去除噪音），同时尽量减少信息的损失。</p><h3 id="Singular-Value-Decomposition-奇异值分解"><a href="#Singular-Value-Decomposition-奇异值分解" class="headerlink" title="Singular Value Decomposition | 奇异值分解"></a>Singular Value Decomposition | 奇异值分解</h3><p>参考：<a href="https://www.cnblogs.com/pinard/p/6251584.html">https://www.cnblogs.com/pinard/p/6251584.html</a></p><p>对于一个 $t\times d$​​ 矩阵 $A$​​​，可以分解为下面三个矩阵：</p><script type="math/tex; mode=display">A_{t\times d}=U_{t\times t}\varSigma _{t\times d}V^T_{d\times d}</script><p>其中 $U$​ 和 $V$​ 都是<strong>酉矩阵</strong>，即满足 $U^TU=I, V^TV=I$​。$\varSigma$​ 一个 $t\times d$​ 矩阵，除了主对角线上的元素以外全为 0，主对角线上的每个元素都称为<strong>奇异值</strong>。</p><p>利用酉矩阵性质得：</p><script type="math/tex; mode=display">A=U\Sigma V^T \Rightarrow A^T=V\Sigma^T U^T \Rightarrow A^TA = V\Sigma^T U^TU\Sigma V^T = V\Sigma^2V^T</script><p>可以看出 $A^TA$ 的特征向量组成的矩阵，就是我们 SVD 中的 $V^T_{d\times d}$​ 矩阵。进一步我们还可以看出我们的特征值矩阵等于奇异值矩阵的平方。</p><p>利用以上原理，我们可以得出 SVD <strong>分解步骤</strong>：</p><ol><li>假设词典矩阵为 $A$，首先求出 $AA^T$，会得到一个 $t\times t$ 的方阵。</li><li>既然是方阵，就可以进行特征值分解，得到 <em>t</em> 个特征值和对应的特征向量。</li><li>将特征值按方差大小排序，用所有的列向量张成一个 $t\times t$ 的矩阵 $U_{t\times t}$。</li><li>同理可以用 $A^TA$ 求出 $d\times d$ 的矩阵 $V^T_{d\times d}$。</li><li>利用前面求出的特征值，开方后得到 $\varSigma _{t\times d}$。​</li></ol><h3 id="利用-SVD-降维"><a href="#利用-SVD-降维" class="headerlink" title="利用 SVD 降维"></a>利用 SVD 降维</h3><p>对于奇异值，它跟我们特征分解中的特征值类似，在奇异值矩阵中也是按照从大到小排列。通常，奇异值的<strong>衰减</strong>得特别快，在很多情况下，前 10% 甚至 1% 的奇异值之和就占了全部的奇异值之和的 99% 以上的比例。</p><p>也就是说，我们也可以用最大的 k 个的奇异值和对应的左右奇异向量来近似描述矩阵。也就是说：</p><script type="math/tex; mode=display">A_{t\times d}=U_{t\times t}\varSigma _{t\times d}V^T_{d\times d}\approx U_{t\times k}\varSigma _{k\times k}V^T_{k\times d}</script><p>其中 <em>k</em> 要比 <em>t</em> 小很多，也就是一个大的矩阵可以用三个小的矩阵，此时存储空间可以大量节省。通常 <em>k</em> 的值即为我们假设的<strong>主题数</strong>。</p><p>SVD 分解后，$U<em>{il}$ 对应第 <em>i</em> 个词和第 <em>l</em> 个词义的相关度。$V</em>{jm}$ 对应第 <em>j</em> 个文档和第 <em>m</em> 个主题的相关度。$\Sigma_{lm}$ 对应第 <em>l</em> 个词义和第 <em>m</em> 个主题的相关度。</p><p>这样我们通过一次 SVD，就可以得到词和词义的相关度，词义和主题的相关度，以及文档和主题的相关度。</p><h3 id="LSI-的使用"><a href="#LSI-的使用" class="headerlink" title="LSI 的使用"></a>LSI 的使用</h3><p>通过计算后，我们关注新的矩阵 $V^T_{k\times d}$​ ，所有的文档已经简化成了和 k 个主题的相关度。假设此时的查询为 $Q=q_1q_2\cdots q_t$​​​​，​其中 <em>q</em> 取 0 或 1，则</p><script type="math/tex; mode=display">Q_{1\times k}=Q_{1\times t}U_{t\times k}\varSigma _{k\times k}</script><p>可将 <em>t</em> 维的查询转化成 <em>k</em> 维的「<strong>与主题的相关度</strong>」，此时就可以与文档进行相似度计算了。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信息检索</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IR</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IR学习笔记 #2 统计语言模型</title>
    <link href="/2021/08/22/IR-Note-2/"/>
    <url>/2021/08/22/IR-Note-2/</url>
    
    <content type="html"><![CDATA[<p>基于对布尔模型的改进，提出一种新的最佳匹配模型。</p><h2 id="Statistical-Language-Models-统计语言模型"><a href="#Statistical-Language-Models-统计语言模型" class="headerlink" title="Statistical Language Models | 统计语言模型"></a>Statistical Language Models | 统计语言模型</h2><p>首先探讨的是 Doc (文档) 的呈现形式，引入 Topic (<strong>主题</strong>) 来表述一个文档的隐含语义，起到索引作用。基于以下两个假设：</p><ul><li>Words common in document are common in topic.</li><li>Words not in document much less likely.</li></ul><p>可以得出，Topic 是由 Doc 中的一些关键词勾勒出来的。于是引入 $P(w|Doc)$ 概率分布表：统计每个词在文档中出现频度（频率）——基于大数定律。</p><p>但 Topic 的难确定性（语义理解不同、可能有多个主题）导致其难以直接计算，因此可以用近似估算。</p><script type="math/tex; mode=display">P\left( w|Topic_D \right) \approx P\left( w|D \right) =tf\left( w,D \right) /len\left( D \right)</script><p>事实上，我们可以认为 Topic 是一种「<strong>语言模型</strong>」，$P\left( w|Topic_D \right)$ 可以认为是在 Topic 下生成该 word 的概率，即该 word 在这个「语言模型」中被生成的概率，故 word 可以不在 Topic 中出现，但也有概率生成。</p><h3 id="Language-Modeling-语言模型化"><a href="#Language-Modeling-语言模型化" class="headerlink" title="Language Modeling | 语言模型化"></a>Language Modeling | 语言模型化</h3><p>定义 <em>M</em> 为我们试图描述的 language (语言)，<em>s</em> 为该语言下观测到的文本串（由许多词条构成）。</p><ul><li><p><em>M</em> can be thought of as a “source” or a generator - a <strong>mechanism</strong> that can spit out strings that are legal in the language.</p></li><li><p>$P(s|M)$ is the probability of getting “<em>s</em>” during random sampling from <em>M</em>.</p></li></ul><p>语言的规模可大可笑，把每种语言的规模缩小为一个 Topic（对应着语料库中的一个文档）；这个 Topic 就决定了任意一个字符串在这个 Topic 所对应的「语言模型」中出现的概率：比如，在一个描述信息检索发展历史的文档中，“Washington” 出现的概率就会远远小于 “Robertson”。</p><p>那么，一旦我们确定了这个 Doc 所对应的「语言模型」<em>M~D~</em> ，而 <em>Q</em> 是用户的 Query，我们是不是可以求出这个「语言模型」下<strong>生成</strong> <em>Q</em> 的概率？概率最大者就是与查询最相关的文档。那么，我们就可以根据 $P(Q|M_D) $ 给所有的 Doc 排序，得到我们的查询结果。</p><h2 id="N-gram-Language-Models-多元语言模型"><a href="#N-gram-Language-Models-多元语言模型" class="headerlink" title="N-gram Language Models | 多元语言模型"></a>N-gram Language Models | 多元语言模型</h2><p>对于一个较长的 Query，我们采用<strong>分词</strong>的方法来计算它的生成概率。为此，首先通过几个例子明确语言模型中 N-gram 的概念：</p><ul><li>Unigram 一元分词，把句子分成一个一个的汉字，如：哈/工/大/深/圳</li><li>Bigram 二元分词，每两个字组成一个词语，如：哈工/工大/大深/深圳</li><li>Trigram 三元分词，每三个字组成一个词语，如：哈工大/工大深/大深圳</li></ul><p>在以上例子中，我们可以知道一个文本串在一元语言中生成的概率将这样计算：</p><script type="math/tex; mode=display">P\left( w_1w_2w_3 \right) =P\left( w_1 \right) \cdot P\left( w_2 \right) \cdot P\left( w_3 \right)</script><p>在二元语言中将这样计算：</p><script type="math/tex; mode=display">P\left( w_1w_2w_3 \right) =P\left( w_1 \right) \cdot P\left( w_2|w_1 \right) \cdot P\left( w_3|w_2 \right)</script><p>可以发现，在 Unigram 中我们假设了单词之间的<strong>独立性</strong>，这就意味着它的本质是词的多项分布，而一个文本串可以看作是这个分布的一个实例。</p><p>对于更多元的分词 N-gram，我们是假设每个单词出现的概率只与它之前的 n-1 个单词<strong>相关</strong>，因此采用了条件概率。事实上，这是一种基于马尔可夫假设的模型，此时的文本串应是有序相关的，这就不属于 BoW 的范畴。</p><p>一般情况下，N 的取值都很小，实际<strong>自然语言处理</strong>应用中最多的是将 N = 3 的三元分词模型。原因如下：</p><ul><li>N 元模型的空间复杂度，是 N 的指数函数，即 $O\left( \left| V \right|^N \right) $，<em>V</em> 是一种语言的词汇量，一般在几万到几十万个。时间复杂度也是一个指数函数$O\left( \left| V \right|^{N-1} \right) $。</li><li>即使使用 N = 4 、N = 5 也不可能覆盖所有词与词之间的相关性。某两个词可能是一段话和一段话之间才会出现的。</li></ul><h3 id="多元语言模型的参数估计"><a href="#多元语言模型的参数估计" class="headerlink" title="多元语言模型的参数估计"></a>多元语言模型的参数估计</h3><p>针对一元模型，只需要统计该「语言模型」生成的文档中，出现该 term 的频率，用频率近似概率即可——<strong>大数定律</strong>。</p><p>这里对二元模型展开探讨：估计 $P\left( w<em>i|w</em>{i-1} \right)$，利用条件概率：</p><script type="math/tex; mode=display">P\left(w_{i} \mid w_{i-1}\right)=\frac{P\left(w_{i-1}, w_{i}\right)}{P\left(w_{i-1}\right)}</script><p>于是，我们只需要统计 $\left(w<em>{i-1}, w</em>{i}\right)$ 的有序词对在文档中的出现次数，再统计 <em>w~i-1~</em> 的出现次数，即可估计其概率。</p><p>然而，存在这样一个问题：在文本中，两个词没有连续出现过，即频度为 0，那么它的概率就是 0 吗？如果词对 $\left(w<em>{i-1}, w</em>{i}\right)$ 和 <em>w~i-1~</em> 的出现次数相同，其概率就是 1 吗？这就涉及到了统计的可靠性问题，也称「<strong>不平滑问题</strong>」。</p><p>解决这些问题的主要方法是<strong>古德-图灵估计</strong>（Good-Turing Estimate）和<strong>卡茨退避法</strong>（Katz backoff）。</p><ul><li><p>对出现次数大于某个阈值的词，频率不下调，即用频率代替概率；</p></li><li><p>对出现次数小于这个阈值的词，频率才下调，利用古德-图灵估计的相对频度来调整；</p></li><li><p>对出现次数等于 0 的词，利用卡茨退避法给予一个比较小的概率值。</p></li></ul><p>这部分的内容属于语料库的自然语言处理，本文中不赘述，仅在后文针对零频问题介绍几种方法。</p><h2 id="Ranking-查询排序问题"><a href="#Ranking-查询排序问题" class="headerlink" title="Ranking | 查询排序问题"></a>Ranking | 查询排序问题</h2><p>当给定查询 <em>Q</em> 时，怎么根据统计语言模型进行排序呢？有三种排序方法，分别是：</p><ol><li>Query-likelihood | <strong>查询似然排序</strong></li></ol><p>为每个 Doc 确定其所对应的 <em>M~D~</em>，而用户的 Query 记为 <em>q</em> = (<em>q~1~</em>, <em>q~2~</em>, …, <em>q~k~</em>)。则该查询在每个文档的「语言模型」下生成的概率可如下计算：</p><script type="math/tex; mode=display">P\left(q_{1} \ldots q_{k} \mid M_{D}\right)=\prod_{i=1}^{k} P\left(q_{i} \mid M_{D}\right)</script><p>将所有计算结果排序，即可得到检索结果。要注意，这种方法对每个 Doc 计算出的概率都独立于其他 Doc，相关文档没有被利用到。</p><ol><li>Document-likelihood | <strong>文档似然排序</strong></li></ol><p>查询似然的翻转版本，为每个 Query 确定其所对应的 <em>M~Q~</em>，计算任意一个文档在该查询的「语言模型」下生成的概率：</p><script type="math/tex; mode=display">P\left(D \mid M_{Q}\right)=\prod_{w \in D} P\left(w \mid M_{Q}\right)</script><p>但是，这种方法存在如下问题：</p><ul><li>文档的长度相差很大，很难比较。</li><li>由于文档中出现的词很多没有出现在查询中，将会出现零频问题。</li><li>将会出现无意义的作弊网页，如将 Query 中的关键词无限重复。</li></ul><p>要解决这些问题，需要引入 Likelihood Ratio (似然比)，对文档长度加以归一。</p><script type="math/tex; mode=display">P\left(M_{Q} \mid D\right)=\frac{P\left(M_{Q}\right) P\left(D \mid M_{Q}\right)}{P(D)} \approx \frac{c \prod_{w \in D} P\left(w \mid M_{Q}\right)}{\prod_{w \in D} P(w \mid G E)}</script><p>其中，对每个文档计算其可能 「生成 <em>M~Q~</em>」的概率，在用贝叶斯公式展开，其中的 $P\left(M_{Q}\right)$ 对于每个文档可视作常数，再由分母的约束，对文档加以限制。</p><ol><li>Ranking by <strong>Model Comparison</strong></li></ol><p>结合前两种方法，提出了<strong>交叉熵</strong>（cross-entropy）的概念：</p><script type="math/tex; mode=display">H\left(M_{Q} \| M_{D}\right)=-\sum_{w} P\left(w \mid M_{Q}\right) \log P\left(w \mid M_{D}\right)</script><p>这种方法同时考虑了查询  <em>M~Q~</em> 和文档  <em>M~D~</em>，直接比较两种模型的相似度。要注意，<em>M~Q~</em> 和 <em>M~D~</em> 在公式中的顺序不能调换。</p><h3 id="Zero-frequency-problem-零频问题"><a href="#Zero-frequency-problem-零频问题" class="headerlink" title="Zero frequency problem | 零频问题"></a>Zero frequency problem | 零频问题</h3><p>有了上述排序模型，现在我们只需要从查询和文档中估算出 <em>M~Q~</em> 和 <em>M~D~</em>。</p><p>在本文的「语言模型」中，我们只需采用<strong>一元分词模型</strong>，独立性和独立分布可以简化许多问题。然而，在<strong>极大似然估计</strong>下，还是有个问题急需解决——零频问题，即有的 term 根本不出现在观测集中，我们该如何估算其概率？</p><p>这里介绍三种 Discounting Methods (折扣法) 来 Smoothing (平滑) ：</p><ol><li><p>Laplace correction：把每个词的词频都加 1，分母的总频数加上词项数 N。但是这种方法不适合较大的词典表。</p></li><li><p>Lindstone correction：把每个词都加一个很小的值 ε，分母的总频数加上 Nε。</p></li><li><p>Absolute Discounting：把词频不等于 0 的词减去一个很小的值 ε，再把减去的总值平均分配到词频为 0 的词上去，不改变分母。</p></li></ol><p>除了折扣法，还有诸如插值法、退避法等方法也可以用于平滑。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信息检索</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IR</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IR学习笔记 #1 概论&amp;布尔模型</title>
    <link href="/2021/08/22/IR-Note-1/"/>
    <url>/2021/08/22/IR-Note-1/</url>
    
    <content type="html"><![CDATA[<p>该笔记是本人于哈尔滨工业大学（深圳）2021 年夏季学期「信息检索」课程的笔记。授课教师为陈清财。算是一门 NLP 入门课程。</p><h2 id="Overview-概论"><a href="#Overview-概论" class="headerlink" title="Overview | 概论"></a>Overview | 概论</h2><h3 id="What’s-Information-Retrieval"><a href="#What’s-Information-Retrieval" class="headerlink" title="What’s Information Retrieval?"></a>What’s Information Retrieval?</h3><p>Indexing, retrieving, and organizing text by probabilistic or statistical.</p><p><strong>Comparing IR to Databases</strong>:</p><div class="table-container"><table><thead><tr><th></th><th>Databases</th><th>IR</th></tr></thead><tbody><tr><td>Data</td><td>Structured</td><td>Unstructured</td></tr><tr><td>Fields</td><td>Clear semantics</td><td>No fields</td></tr><tr><td>Queries</td><td>Defined(SQL)</td><td>Free text (自然语言) + Boolean</td></tr><tr><td>Recoverability</td><td>Critical</td><td>Downplayed</td></tr><tr><td>Matching</td><td>Exact</td><td>Imprecise (need to measure)</td></tr></tbody></table></div><h3 id="Basic-Approach-to-IR-信息检索的基本方法"><a href="#Basic-Approach-to-IR-信息检索的基本方法" class="headerlink" title="Basic Approach to IR | 信息检索的基本方法"></a>Basic Approach to IR | 信息检索的基本方法</h3><p>大多数成功的方法都是基于概论统计，而不是自然语言理解。因为自然语言在缺少约束的状态（unrestricted domains）下具有极大不确定性，而人工标注又十分昂贵。</p><p><strong>统计方法的核心思想</strong>：Relevant (相关) Items are Similar (相似). Usually look for documents matching query words.</p><p>The similarity can be measured by: </p><ul><li>String matching/comparison (字符串匹配)</li><li>Same vocabulary (词汇) </li><li>Probability that documents arise from same model (文档出现概率)</li><li>Same meaning of text (语义) — Hard to achieve</li></ul><h4 id="“Bag-of-Words”-词袋"><a href="#“Bag-of-Words”-词袋" class="headerlink" title="“Bag of Words” | 词袋"></a>“Bag of Words” | 词袋</h4><p>Compares words <strong>without regard to order</strong>.</p><p><strong>Stop word (停用词)</strong>：屏蔽对文章分类无效的高频词。</p><h3 id="Retrieval-Models-基础检索模型"><a href="#Retrieval-Models-基础检索模型" class="headerlink" title="Retrieval Models | 基础检索模型"></a>Retrieval Models | 基础检索模型</h3><p>检索模型：建立在 Doc 和 Query 之间的模型，用于描述相似性、排序相似性。</p><p>检索变量：queries (查询), documents (文档), terms (术语), relevance<br>judgments (相关性判别)。</p><h4 id="Exact-vs-Best-Match"><a href="#Exact-vs-Best-Match" class="headerlink" title="Exact vs. Best Match"></a>Exact vs. Best Match</h4><p>精确匹配：二值 (0/1) 匹配，检索结果无序，可以用 boolean queries (布尔查询)、proximity operators (邻接算子)、simple regular expressions (正则表达式)。对文档量级有限制。</p><p>最佳匹配：相似度 (0~1) 匹配，检索结果按照相似度排序。</p><h2 id="Boolean-Retrieval-布尔模型"><a href="#Boolean-Retrieval-布尔模型" class="headerlink" title="Boolean Retrieval | 布尔模型"></a>Boolean Retrieval | 布尔模型</h2><p>一种最常见的精确匹配模型，通常结果是无序呈现（unranked），有的模型会增加简单的排序。</p><p>精确匹配模型最直接的想法：<strong>线性扫描</strong>，从头到尾扫描文档集，对每个文档都查看是否包含关键词。在 Unix/Linux 系统中的文本扫描命令 grep 做的就是这种工作。然而，当需要检索的文档规模非常大时，这种线性扫描的方式的效率会变得非常低下。</p><h4 id="如何实现-Boolean-Retrieval"><a href="#如何实现-Boolean-Retrieval" class="headerlink" title="如何实现 Boolean Retrieval"></a>如何实现 Boolean Retrieval</h4><p>需要实现如下的模块：</p><ul><li>Term-document incidence (<strong>词典表</strong>): 类似 index (索引) 的文档呈现的形式，一个矩阵中，用 0 和 1 标记文档中出现的 term (词项)。</li><li><p>Boolean queries (布尔查询): AND, OR, AND-NOT.</p></li><li><p>Incidence vector (关联向量): 0/1 vector, bitwise AND。</p></li><li><p>Proximity operators (邻接算子): phrases - “”、same sentence - “ /s ”、same paragraph - “/p” 等等。</p></li></ul><h4 id="实现中的要点"><a href="#实现中的要点" class="headerlink" title="实现中的要点"></a>实现中的要点</h4><p>在词典表实现中，为了避免矩阵过大，还可以引入 inverted index (<strong>倒排索引</strong>) 存储矩阵，这里不再赘述。下面介绍两个实现步骤中的概念。</p><p><strong>token (词条) vs. term (词项)</strong>：</p><p>对于英文文本而言，词条就是根据空格把单词一个一个地提取出来，把原始文本分割开。词项则是更加统一规范的的词条。</p><p>例如在文本中可能出现 “apple”、“apples”、“Apple” 这类 token，但我们知道这几个 token 都是表达苹果（apple）的意思，因此，在构建索引的时候通常会把这几个 token 统一还原为 “apple”，只为 “apple” 建立索引项，那么 “apple” 就是一个 term 了。</p><h4 id="Features-to-Note-about-Queries"><a href="#Features-to-Note-about-Queries" class="headerlink" title="Features to Note about Queries"></a>Features to Note about Queries</h4><ul><li>Queries are developed incrementally. 查询表达式是可增长的，往往一直增加直到查询出正确结果。</li><li>Queries are complex. 用到了一定公式，对初学者不友好。</li><li>Queries are long (av. 9-10 words). 不同于通常的自然语言询问，只需要 1-2 个单词。</li></ul>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信息检索</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IR</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo配置与扩展</title>
    <link href="/2021/08/21/Hexo-Configuration/"/>
    <url>/2021/08/21/Hexo-Configuration/</url>
    
    <content type="html"><![CDATA[<p>Hello My World 的姊妹篇。</p><p>本站基于 Hexo + GitHub 搭建，采用 Fluid 主题。</p><p>这篇文章记录了博客的配置历程，包括：主题配置、域名配置、功能扩展。</p><h2 id="主题配置"><a href="#主题配置" class="headerlink" title="主题配置"></a>主题配置</h2><p>本站采用的是 Fluid 主题，以下的配置在路径 <code>hewei2001/_config.fluid.yml</code> 中可以实现。该文件的介绍参见 <a href="https://hexo.fluid-dev.com/docs/guide/#%E6%96%87%E7%AB%A0%E9%A1%B5%E9%A1%B6%E9%83%A8%E5%A4%A7%E5%9B%BE">主题配置指南</a> 。以下仅介绍部分较为特殊的配置，其他内容可在指南中找到。</p><h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><p><code>lib</code>: 选择生成高亮的库，可选项有 highlightjs 和 prismjs，对应下面两组配置。</p><p>这里选择 <code>highlightjs</code>，将 <code>style</code> 修改为 <code>Night Owl</code> 风格，将 <code>bg_color</code> 修改为 <code>true</code> 以适配暗色代码框。</p><p>其他尝试过的主题还有 <code>Atom One Dark Reasonable</code>、<code>Vs 2015</code>、<code>Github Dark Dimmed</code>，都是不错的暗色风格。</p><p>唯一的缺憾可能是 Fluid 主题下不支持 Mac 风格的代码框，据说未来的版本会增加。</p><h3 id="评论功能"><a href="#评论功能" class="headerlink" title="评论功能"></a>评论功能</h3><p>Valine 是国内的一款极简风格的评论软件，也是 Fluid 支持的评论软件之一。在 <code>comment</code> 中选择 <code>valine</code>，之后找到相应的配置区域进行如下操作：</p><p>进入官网 <a href="https://leancloud.cn/">LeanCloud</a> 完成注册，然后在控制台创建一个项目 <code>Blog.Comments</code> 后，获取密钥（App ID 和 App Key），在对应位置填入。其他内容选项可以在官网找到说明。</p><h3 id="访问人数统计"><a href="#访问人数统计" class="headerlink" title="访问人数统计"></a>访问人数统计</h3><p>Fluid 主题提供两种网站的 PV、UV 统计数来源：<a href="https://www.leancloud.cn/">LeanCloud</a> 与 <a href="http://busuanzi.ibruce.info/">不蒜子</a>。不蒜子不需要申请账号，直接开启即可，但有时候会响应缓慢拖慢整个页面加载。LeanCloud 使用前需要申请账号，由于前面使用评论功能时已经注册，我们这边直接使用就行。</p><p>在控制台创建一个项目 <code>Blog.Counter</code> 后，获取密钥（App ID 和 App Key）和大陆服务器地址，填入 <code>web_analytics</code> 配置项中 <code>leancloud</code> API 相关参数。</p><h3 id="内置-Tag-插件"><a href="#内置-Tag-插件" class="headerlink" title="内置 Tag 插件"></a>内置 Tag 插件</h3><p>Fluid 内置了一些 Tag 插件，用于实现 Markdown 不容易生成的样式，以下仅列出两种常用的使用语法，添加在 md 文件中：</p><ol><li>脚注</li></ol><figure class="highlight markdown"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs markdown">正文[^1]<br><br><span class="hljs-section">## 参考</span><br>[<span class="hljs-symbol">^1</span>]: <span class="hljs-link">参考资料1</span><br>[<span class="hljs-symbol">^2</span>]: <span class="hljs-link">参考资料2</span><br></code></pre></div></td></tr></table></figure><ol><li>Tag 便签</li></ol><p>在 markdown 中加入如下的代码来使用便签：</p><figure class="highlight markdown"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs markdown">&#123;% note success %&#125;<br>文字 或者 <span class="hljs-code">`Markdown`</span> 均可<br>可选便签：primary/secondary/success/danger/warning/info/light<br>&#123;% endnote %&#125;<br></code></pre></div></td></tr></table></figure><p>或者使用 HTML 形式：</p><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;note note-primary&quot;</span>&gt;</span>标签<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br></code></pre></div></td></tr></table></figure><h3 id="Latex-数学公式"><a href="#Latex-数学公式" class="headerlink" title="Latex 数学公式"></a>Latex 数学公式</h3><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">post:</span><br>  <span class="hljs-attr">math:</span><br>    <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br>    <span class="hljs-attr">specific:</span> <span class="hljs-literal">false</span><br>    <span class="hljs-attr">engine:</span> <span class="hljs-string">mathjax</span> <span class="hljs-string">或</span> <span class="hljs-string">katex</span><br></code></pre></div></td></tr></table></figure><p>其中 <code>specific</code> 建议开启：当为 true 时，只有在文章 Front-matter 里指定 <code>math: true</code> 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度。</p><p>由于 Hexo 默认的 Markdown 渲染器不支持复杂公式，所以必须更换渲染器。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ npm uninstall hexo-renderer-marked --save  <span class="hljs-comment"># 卸载原渲染器</span><br>$ npm install hexo-renderer-kramed --save    <span class="hljs-comment"># mathjax</span><br>$ npm install @upupming/hexo-renderer-markdown-it-plus --save  <span class="hljs-comment"># katex</span><br></code></pre></div></td></tr></table></figure><p>这里选择 MathJax，是因为对 LaTeX 语法支持全面，且右键点击公式有扩展功能。</p><h2 id="域名配置"><a href="#域名配置" class="headerlink" title="域名配置"></a>域名配置</h2><h3 id="部署到-Coding-Pages"><a href="#部署到-Coding-Pages" class="headerlink" title="部署到 Coding Pages"></a>部署到 Coding Pages</h3><p>Coding 可以算是国内的 GitHub，尽管并不是特别流行，但部署到上面可以使国内访问速度更快，还可以提交百度收录（GitHub 禁止了百度的爬取）。</p><p>注意：由于 Coding 在前段时间改版后，原有的个人版 Pages 下架，以企业版的形式重新开放，新版的静态网站服务需调用腾讯云对象存储 COS、内容分发网络 CDN、SSL 证书产品等资源，其中 COS 和 CDN 采用用量<strong>计费模式</strong>。故本博客暂不采用 Coding 部署。</p><h3 id="添加百度谷歌收录"><a href="#添加百度谷歌收录" class="headerlink" title="添加百度谷歌收录"></a>添加百度谷歌收录</h3><p>如果仅部署在 GitHub Pages，是无法被百度收录的，因为 GitHub 禁止了百度爬虫，最常见的解决办法是双线部署到 Coding Pages 和 GitHub Pages。</p><p>本站暂不考虑。</p><h3 id="自定义域名"><a href="#自定义域名" class="headerlink" title="自定义域名"></a>自定义域名</h3><p>有了 GitHub Pages 服务器自带的域名后，还可以到阿里云再购买一个自定义域名，然后将域名解析到博客的域名，具体过程如下：</p><ol><li>注册阿里云，实名认证后在购买下 hwcoder.top 域名。</li><li>打开域名控制台，进入<strong>域名解析</strong>列表，进入新买的域名，添加两条记录：<ul><li>主机记录：@；记录类型：A；记录值为 GitHub Pages 域名的 IP。</li><li>主机记录：www；记录类型：CNAME；记录值为 GitHub Pages 域名。</li></ul></li><li>在路径 <code>hewei2001/source</code> 下新建一个 <code>CNAME</code> 文件，里面填写我们买的域名，注意文件不需要任何后缀。</li><li>GitHub 中打开对应仓库，在 Setting 中找到 Pages，添加 Custom Domain 为新买的域名，旁边的一个 <code>Enforce HTTPS</code> 勾选后我们的网站就变为 <a href="https://hwcoder.top。">https://hwcoder.top。</a></li><li>路径 <code>hewei2001/_config.yml</code> 的<code>#URL</code> 部分，更改为新域名。</li></ol><h2 id="其他功能扩展"><a href="#其他功能扩展" class="headerlink" title="其他功能扩展"></a>其他功能扩展</h2><p>以下配置是在 Fluid 主题中不具有的功能，通过各种插件实现。</p><h3 id="备份博客到-GitHub"><a href="#备份博客到-GitHub" class="headerlink" title="备份博客到 GitHub"></a>备份博客到 GitHub</h3><p>由于 Hexo 博客是静态托管的，所有的原始数据都保存在本地，如果哪一天电脑坏了，或者是误删了本地数据就很危险了。</p><p>GitHub 上可以找到一个 <code>hexo-git-backup</code> 插件，但似乎已经不再更新了，仅支持 Hexo 3.x.x 版本，尝试后放弃。</p><h3 id="压缩静态资源"><a href="#压缩静态资源" class="headerlink" title="压缩静态资源"></a>压缩静态资源</h3><p>博客中有大量 HTML、CSS、JS 文件，这些文件为了阅读方便会加入许多回车和空行，但在页面解析时其实会浪费部分时间，此外如果有许多插图，也会拖慢网页加载，并占据 GitHub 仓库的存储空间。</p><p>目前有关插件有 <code>gulp</code>、<code>hexo-neat</code>、<code>hexo-all-minifier</code>。推荐采用集成度比较高的 <code>hexo-all-minifier</code> 来实现，由于在安装依赖包过程报错，本站最终采用了 <code>hexo-neat</code>。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ npm install hexo-all-minifier --save  <span class="hljs-comment"># 出现 npm ERR! code ELIFECYCLE 错误</span><br>$ npm install hexo-neat --save <span class="hljs-comment"># 换成这个后成功安装</span><br></code></pre></div></td></tr></table></figure><p>之后在配置文件 <code>hewei2001/_config.yml</code> 中增加如下内容就行：</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-comment"># hexo-neat</span><br><span class="hljs-comment">## Docs: https://github.com/rozbo/hexo-neat</span><br><span class="hljs-attr">neat_enable:</span> <span class="hljs-literal">true</span><br><span class="hljs-comment"># 压缩 html</span><br><span class="hljs-attr">neat_html:</span><br>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">exclude:</span><br><span class="hljs-comment"># 压缩 css  </span><br><span class="hljs-attr">neat_css:</span><br>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">exclude:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;**/*.min.css&#x27;</span><br><span class="hljs-comment"># 压缩 js</span><br><span class="hljs-attr">neat_js:</span><br>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">mangle:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">output:</span><br>  <span class="hljs-attr">compress:</span><br>  <span class="hljs-attr">exclude:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;**/*.min.js&#x27;</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;**/jquery.fancybox.pack.js&#x27;</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&#x27;**/index.js&#x27;</span> <br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术经验</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello My World</title>
    <link href="/2021/08/19/Hello-My-World/"/>
    <url>/2021/08/19/Hello-My-World/</url>
    
    <content type="html"><![CDATA[<p>谨以此文纪念该个人网站的诞生。</p><p>本站基于 Hexo + GitHub 搭建，采用 Fluid 主题。</p><p>这篇文章记录了博客的搭建历程，以及 Hexo 的使用指南。</p><h2 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h2><p>早在大学入学时，夏老师就告知了个人博客的重要性。</p><p>期间也看过许多漂亮的个人网站，也看到很多大神的技术博客，偶尔会心动一下。</p><p>于是乎，咕到了大二快结束时，打开了这个新世界的大门。</p><h2 id="搭建历程"><a href="#搭建历程" class="headerlink" title="搭建历程"></a>搭建历程</h2><h3 id="1-安装-Node-js"><a href="#1-安装-Node-js" class="headerlink" title="1. 安装 Node.js"></a>1. 安装 Node.js</h3><p>官网：<a href="nodejs.org">nodejs.org</a></p><p>安装后在 cmd 命令行输入 <code>node -v</code> 即可查看版本。</p><h3 id="2-注册-GitHub"><a href="#2-注册-GitHub" class="headerlink" title="2. 注册 GitHub"></a>2. 注册 GitHub</h3><p>创建仓库：<a href="https://github.com/hewei2001/hewei2001.github.io">https://github.com/hewei2001/hewei2001.github.io</a></p><p>此时在浏览器中已经可以访问域名：<a href="https://hewei2001.github.io">https://hewei2001.github.io</a></p><p>如果仓库取了其他名字，最后访问的域名会是：<a href="https://用户名.github.io/仓库名/">https://用户名.github.io/仓库名/</a></p><h3 id="3-下载-Git"><a href="#3-下载-Git" class="headerlink" title="3. 下载 Git"></a>3. 下载 Git</h3><p>官网：<a href="gitforwindows.org">gitforwindows.org</a></p><p>安装时按照默认配置即可，其中有个 MinTTY 终端模拟器的选项会默认选上，如果不选则会使用 Windows 自带的终端 cmd 显示 Git Bash。</p><p>安装后在 cmd 命令行输入 <code>git</code> 即可调出功能目录。</p><p>此后就在 cmd 中配置 Git 个人基本信息（绑定 GitHub）：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">git config --global user.name <span class="hljs-string">&quot;hewei2001&quot;</span><br>git config --global user.email <span class="hljs-string">&quot;631670924@qq.com&quot;</span><br></code></pre></div></td></tr></table></figure><p>配置完才后续才可以正确部署远程仓库（详见 Git 教学）。</p><h3 id="4-配置-GitHub-SSH"><a href="#4-配置-GitHub-SSH" class="headerlink" title="4. 配置 GitHub SSH"></a>4. 配置 GitHub SSH</h3><p>该步骤旨在建立当前主机与 GitHub 的安全连接，以后提交/拉取仓库才不需要重复输入密码。</p><p>打开 Git Bash 输入命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ ssh-keygen -t rsa -C <span class="hljs-string">&quot;631670924@qq.com&quot;</span> <span class="hljs-comment"># 获取 SSH Key</span><br></code></pre></div></td></tr></table></figure><p>完成后，在对应路径下找到 .ssh 文件夹中的 id_rsa.pub 文件，用记事本打开拷贝。</p><p>在 GitHub 个人设置中找到 SSH，新建，输入 Key。</p><p>配置后可以用如下命令测试是否成功：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ ssh -T git@github.com<br><span class="hljs-comment"># 运行结果出现类似如下即表示成功</span><br><span class="hljs-comment"># Hi hewei2001! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span><br></code></pre></div></td></tr></table></figure><h3 id="5-安装-Hexo"><a href="#5-安装-Hexo" class="headerlink" title="5. 安装 Hexo"></a>5. 安装 Hexo</h3><p>官网：<a href="hexo.io">hexo.io</a>，有中文官网。</p><p>在电脑中新建 Blog 文件夹，如 <code>D:\Blog</code>。</p><p>在 cmd 命令行打开 D 盘，用 <code>cd Blog</code>命令进入 Blog 子目录。或者在文件夹路径栏直接输入 <code>cmd</code>。</p><p>输入 Hexo 官网上的全局安装命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ npm install hexo-cli -g<br></code></pre></div></td></tr></table></figure><p>输入初始化部署命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo init hewei2001<br></code></pre></div></td></tr></table></figure><p>即可在 Blog 目录下新建<strong>博客文件夹</strong> hewei2001。用 <code>cd hewei2001</code>命令进入博客子目录。</p><p>输入安装 Node.js 包管理器命令，安装所有的依赖：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ npm install<br></code></pre></div></td></tr></table></figure><p>输入生成本地预览命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo s<br></code></pre></div></td></tr></table></figure><p>默认会生成 <code>localhost:4000</code> 端口的网址，在浏览器中可以访问。</p><h3 id="6-安装编辑器"><a href="#6-安装编辑器" class="headerlink" title="6. 安装编辑器"></a>6. 安装编辑器</h3><p>主要用于编写文档和修改配置，这里选择 VsCode 即可，打开路径 <code>hewei2001/source/_posts/hello-world.md</code>，随便修改内容后保存。</p><p>在 hewei2001 目录中运行 Git Bash。</p><p>依次输入清理缓存、生成博客文件（静态页面）、<strong>生成本地预览</strong>命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo cl <span class="hljs-comment"># 表示 clean</span><br>$ hexo g  <span class="hljs-comment"># 表示 generate</span><br>$ hexo s  <span class="hljs-comment"># 表示 server</span><br></code></pre></div></td></tr></table></figure><p>在浏览器中访问即可查看更改。之后按下 Ctrl + C 即可退出预览进程。</p><h3 id="7-将-Hexo-发布至-GitHub"><a href="#7-将-Hexo-发布至-GitHub" class="headerlink" title="7. 将 Hexo 发布至 GitHub"></a>7. 将 Hexo 发布至 GitHub</h3><p>打开路径 <code>hewei2001/_config.yml</code>，更改基础参数。</p><ul><li><code>#Site</code> 部分的站点描述自行修改</li><li><code>#URL</code> 部分，将链接改为 <a href="https://hewei2001.github.io">https://hewei2001.github.io</a> </li><li><code>#Deployment</code> 部分<ul><li><code>type</code> 改为 git</li><li><code>repo</code> 改为 <a href="https://github.com/hewei2001/hewei2001.github.io.git">https://github.com/hewei2001/hewei2001.github.io.git</a></li><li><code>branch</code> 改为 gh-pages</li></ul></li></ul><p>进入 Hexo 官网，复制 hexo-deployer-git 的安装命令，在 Git Bash 中安装。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ npm install hexo-deployer-git --save<br></code></pre></div></td></tr></table></figure><p>依次输入清理缓存、生成博客文件（静态页面）、<strong>提交远程仓库</strong>命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo cl<br>$ hexo g<br>$ hexo d  <span class="hljs-comment"># 表示 deploy，安装了上面的 hexo-deployer-git 才可用</span><br></code></pre></div></td></tr></table></figure><p>初次使用该操作可能会弹出一个 GitHub 登录界面，用于当前主机的身份验证。</p><p>在浏览器中访问 <a href="https://hewei2001.github.io">https://hewei2001.github.io</a>  即可查看站点。</p><h2 id="Hexo-使用"><a href="#Hexo-使用" class="headerlink" title="Hexo 使用"></a>Hexo 使用</h2><p>以下介绍其他常用的 Hexo 操作命令，需要在博客文件夹下打开 Git Bash 使用。</p><h3 id="新建文章"><a href="#新建文章" class="headerlink" title="新建文章"></a>新建文章</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo n <span class="hljs-string">&quot;文章名&quot;</span> <span class="hljs-comment"># 代表 new</span><br></code></pre></div></td></tr></table></figure><p>文章名不需要文件后缀，会自动生成 Markdown 文件，且带有预先定义的参数（在 Front-matter 中），如标题、日期、标签等。</p><p>以下是一些常用的参数及默认设置：</p><div class="table-container"><table><thead><tr><th>参数</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td><code>title</code></td><td>标题</td><td>文章的文件名</td></tr><tr><td><code>date</code></td><td>建立日期</td><td>文件建立日期</td></tr><tr><td><code>updated</code></td><td>更新日期</td><td>文件更新日期</td></tr><tr><td><code>comments</code></td><td>开启文章的评论功能</td><td>true</td></tr><tr><td><code>categories</code></td><td>分类（不适用于分页）</td><td>无</td></tr><tr><td><code>tags</code></td><td>标签（不适用于分页）</td><td>无</td></tr><tr><td><code>excerpt</code></td><td>摘要，优先于 <code>&lt;!-- more --&gt;</code></td><td>无</td></tr><tr><td><code>index_img</code></td><td>文章封面图，用 /img/ 相对路径</td><td>无</td></tr><tr><td><code>math</code></td><td>公式转换，关闭时加速加载</td><td>true</td></tr><tr><td><code>sticky</code></td><td>文章置顶，数值越大越靠前</td><td>无</td></tr></tbody></table></div><p>注意 Hexo 采用的是 GitHub Favored Markdown，书写规范与标准 Markdown 有微小区别，可以查阅 GitHub 上的说明。</p><h3 id="布局管理"><a href="#布局管理" class="headerlink" title="布局管理"></a>布局管理</h3><p>在上面新建文章时，我们还可以制定布局：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo n [layout] <span class="hljs-string">&quot;文章名&quot;</span> <br></code></pre></div></td></tr></table></figure><p>其中，<code>layout</code> 可替换为 post（文章，默认）、draft（草稿）、page（页面）。默认值可以在配置文件中修改 <code>default_layout</code> 来改动。不同布局的文件会存储在不同位置。</p><p>对于 page 布局，Hexo 会创建一个以标题为名字的目录，并在目录中放置一个 index.md 文件，页面布局顾名思义就是用来 DIY 我们博客页面的，不会被渲染。 </p><p>对于 draft 布局，在建立时会被保存到 <code>source/drafts</code> 文件夹中，但不会显示在页面上，如果我们不想某一篇文章显示在页面上，也可以把它移动到该文件夹中。</p><p>此外，还有关于 draft 的一些操作：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hexo s --draft  <span class="hljs-comment"># 在服务器预览时加入草稿文件</span><br>$ hexo publish [layout] <span class="hljs-string">&quot;文章名&quot;</span>  <span class="hljs-comment"># 将草稿发布为 post 或 page</span><br></code></pre></div></td></tr></table></figure><h3 id="修改默认布局"><a href="#修改默认布局" class="headerlink" title="修改默认布局"></a>修改默认布局</h3><p>上述布局管理中的三种布局，还对应这三种模板，这些模板可以在 <code>hewei2001/scaffolds</code> 路径下找到，我们可以提前修改 post 模板，这样每次新建文章时就不需要自己添加 Front-matter 了。</p><h3 id="分类和标签"><a href="#分类和标签" class="headerlink" title="分类和标签"></a>分类和标签</h3><p>在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 <code>Foo, Bar</code> 不等于 <code>Bar, Foo</code>；而标签没有顺序和层次。</p><p>首先要创建「分类」和「标签」本身所在的<strong>页面</strong>，打开博客文件夹，执行 <code>hexo new page xxx</code> 命令。Fluid 主题不需要，已经自带「分类」、「标签」和「归档」页面了，故这里不展开介绍。</p><p>此后就可以 post 布局的文章指定分类和标签了，也需要在对应文章的 Front-matter 中设置。Hexo 不支持给一篇文章指定多个同级分类，因此需要规划好。下面是指定方法：</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">categories:</span><br> <span class="hljs-bullet">-</span> <span class="hljs-string">技术经验</span><br> <span class="hljs-bullet">-</span> <span class="hljs-string">博客</span>  <span class="hljs-comment"># 「博客」会作为「技术经验」的子类</span><br><span class="hljs-attr">tags:</span><br> <span class="hljs-bullet">-</span> <span class="hljs-string">Hexo</span><br> <span class="hljs-bullet">-</span> <span class="hljs-string">Git</span>  <span class="hljs-comment"># 「Hexo」与「Git」是同级标签</span><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术经验</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
