<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/logo.jpg"><link rel="icon" href="/img/logo.jpg"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#01213a"><meta name="author" content="Wei He"><meta name="keywords" content="Computer Science and Technology, Machine Learning, Deep Learning, Computer Vision, Natural Language Processing"><meta name="description" content="2024 年 9 月 12 日，OpenAI 发布了最新的 o1 系列模型，在推理要求高的复杂任务上远超此前的 GPT-4o。本文根据一些已有的现象，猜测一下 OpenAI o1 背后的技术原理。"><meta property="og:type" content="article"><meta property="og:title" content="OpenAI o1 系列模型背后的技术猜测"><meta property="og:url" content="https://hwcoder.top/OpenAI-o1-Series"><meta property="og:site_name" content="Hwcoder - Life Oriented Programming"><meta property="og:description" content="2024 年 9 月 12 日，OpenAI 发布了最新的 o1 系列模型，在推理要求高的复杂任务上远超此前的 GPT-4o。本文根据一些已有的现象，猜测一下 OpenAI o1 背后的技术原理。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hwcoder.top/img/home/OpenAI.jpg"><meta property="article:published_time" content="2024-09-13T11:53:09.000Z"><meta property="article:modified_time" content="2024-12-14T14:05:25.092Z"><meta property="article:author" content="Wei He"><meta property="article:tag" content="LLMs"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://hwcoder.top/img/home/OpenAI.jpg"><title>OpenAI o1 系列模型背后的技术猜测 | Hwcoder - Life Oriented Programming</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="/css/mac.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var dntVal,CONFIG={hostname:"hwcoder.top",root:"/",version:"1.9.5",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h2, h3",placement:"left",visible:"always",icon:"§"},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4",collapseDepth:3},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:null,google:{measurement_id:null},tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"XGNf4GEnaFLiUijMUvz8HSBF-gzGzoHsz",app_key:"JPeVLcug6EcWdBTpGrDJSdKi",server_url:"https://xgnf4gen.lc-cn-n1-shared.com",path:"window.location.pathname",ignore_local:!0}},search_path:"/local-search.xml",include_content_in_search:!0};CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script async>Fluid.ctx.dnt||Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=",function(){function a(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],a("js",new Date),a("config","")})</script><meta name="generator" content="Hexo 5.4.2"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Hwcoder</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/bg/other.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="OpenAI o1 系列模型背后的技术猜测"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2024-09-13 19:53" pubdate>2024年9月13日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 4k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 23 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="论文阅读" id="heading-7545c85b0df88485ddabffad9bb45965" role="tab" data-toggle="collapse" href="#collapse-7545c85b0df88485ddabffad9bb45965" aria-expanded="true">论文阅读 <span class="list-group-count">(5)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-7545c85b0df88485ddabffad9bb45965" role="tabpanel" aria-labelledby="heading-7545c85b0df88485ddabffad9bb45965"><div class="category-post-list"></div><div class="category-sub row nomargin-x"><a class="category-subitem list-group-item category-item-action col-10 col-md-11 col-xm-11" title="前沿热点" id="heading-f544ecc494bb390491f578dd08b7a8b2" role="tab" data-toggle="collapse" href="#collapse-f544ecc494bb390491f578dd08b7a8b2" aria-expanded="true">前沿热点 <span class="list-group-count">(2)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-f544ecc494bb390491f578dd08b7a8b2" role="tabpanel" aria-labelledby="heading-f544ecc494bb390491f578dd08b7a8b2"><div class="category-post-list"><a href="/OpenAI-o1-Series" title="OpenAI o1 系列模型背后的技术猜测" class="list-group-item list-group-item-action active"><span class="category-post">OpenAI o1 系列模型背后的技术猜测</span> </a><a href="/OpenAI-o3-Series" title="OpenAI o3 与 Monte-Carlo 思想" class="list-group-item list-group-item-action"><span class="category-post">OpenAI o3 与 Monte-Carlo 思想</span></a></div></div></div><div class="category-sub row nomargin-x"><a class="category-subitem collapsed list-group-item category-item-action col-10 col-md-11 col-xm-11" title="推荐系统" id="heading-b89d9a904b3b7c6f47d8363671ec6140" role="tab" data-toggle="collapse" href="#collapse-b89d9a904b3b7c6f47d8363671ec6140" aria-expanded="false">推荐系统 <span class="list-group-count">(2)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse" id="collapse-b89d9a904b3b7c6f47d8363671ec6140" role="tabpanel" aria-labelledby="heading-b89d9a904b3b7c6f47d8363671ec6140"><div class="category-post-list"><a href="/Uplift-Paper-Collection" title="Uplift Recommendation 论文汇总" class="list-group-item list-group-item-action"><span class="category-post">Uplift Recommendation 论文汇总</span> </a><a href="/Uplift-Modeling" title="浅谈 Uplift Modeling" class="list-group-item list-group-item-action"><span class="category-post">浅谈 Uplift Modeling</span></a></div></div></div><div class="category-sub row nomargin-x"><a class="category-subitem collapsed list-group-item category-item-action col-10 col-md-11 col-xm-11" title="自然语言处理" id="heading-f48c43f5fd14bfd8a5057a0131e7aa20" role="tab" data-toggle="collapse" href="#collapse-f48c43f5fd14bfd8a5057a0131e7aa20" aria-expanded="false">自然语言处理 <span class="list-group-count">(1)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse" id="collapse-f48c43f5fd14bfd8a5057a0131e7aa20" role="tabpanel" aria-labelledby="heading-f48c43f5fd14bfd8a5057a0131e7aa20"><div class="category-post-list"><a href="/FudanNLP-LI-Bib" title="复旦 NLP-LI 课题组近期论文索引" class="list-group-item list-group-item-action"><span class="category-post">复旦 NLP-LI 课题组近期论文索引</span></a></div></div></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">OpenAI o1 系列模型背后的技术猜测</h1><p class="note note-info">本文最后更新于：2024年12月14日 晚上</p><div class="markdown-body"><p>首先是两篇官方博客原文：</p><ul><li><p><a target="_blank" rel="noopener" href="https://openai.com/index/introducing-openai-o1-preview/">Introducing OpenAI o1 | OpenAI</a></p></li><li><p><a target="_blank" rel="noopener" href="https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/">OpenAI o1-mini | OpenAI</a></p></li></ul><h2 id="openai-o1-背后的技术">OpenAI o1 背后的技术</h2><p>结合以下几个现象，来猜测一下 OpenAI o1 背后的秘密：</p><p>第一，是两个月前发布的 <strong>CriticGPT</strong>，探索了 Text Critic 作为反馈或奖励，会优于 Numerical Value 作为奖励的效果。P.S. Google 前不久也发了一篇 GenRM，看来也在往这个方向上靠。</p><blockquote><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.00215">LLM Critics Help Catch LLM Bugs</a></p></blockquote><p>第二，是模型的<strong>推理速度和价格</strong>，官方博客中的一个演示中，GPT-4o 用时 3s，o1-mini 用时 9s，o1-preview 用时 15s。而在官网的价格表中，我汇总了下表。如果认为 4o 和 o1 的规模相近，4o-mini 和 o1-mini 的规模相近，那么<strong>增加的时间和成本只可能是 Test-time Compute 带来的</strong>。</p><table><thead><tr class="header"><th style="text-align:center">模型</th><th style="text-align:center">输入价格</th><th style="text-align:center">输出价格</th></tr></thead><tbody><tr class="odd"><td style="text-align:center">gpt-4o-2024-08-06</td><td style="text-align:center">$2.50 / 1M input tokens</td><td style="text-align:center">$10.00 / 1M output tokens</td></tr><tr class="even"><td style="text-align:center">gpt-4o-mini-2024-07-18</td><td style="text-align:center">$0.150 / 1M input tokens</td><td style="text-align:center">$0.600 / 1M output tokens</td></tr><tr class="odd"><td style="text-align:center">o1-preview-2024-09-12</td><td style="text-align:center">$15.00 / 1M input tokens</td><td style="text-align:center">$60.00 / 1M output tokens</td></tr><tr class="even"><td style="text-align:center">o1-mini-2024-09-12</td><td style="text-align:center">$3.00 / 1M input tokens</td><td style="text-align:center">$12.00 / 1M output tokens</td></tr></tbody></table><p>第三，是<strong>模型表现</strong>，博客中提到 o1 在推理密集的复杂任务上取得了增益，但在文本相关的简单任务没有太多区别。这也印证了第一点，<strong>这种 Critic 训练策略可能只适合于推理任务</strong>，文本任务可能区分度没有那么大（分不出好坏，不好给奖励），导致没优势。</p><blockquote><p>Similar to o1-preview, o1-mini is preferred to GPT-4o in reasoning-heavy domains, but is not preferred to GPT-4o in language-focused domains.</p><p>与 o1-preview 类似，o1-mini 在偏重推理的领域优于 GPT-4o，但在偏重语言的领域则不优于 GPT-4o。</p></blockquote><p><img src="/img/blog/OpenAI-o1-Series-images/fig1.jpg" srcset="/img/loading.gif" lazyload alt="OpenAI 在各个领域上做了人类偏好的评估，可以看到前两个任务上，o1 vs. 4o 胜率低于 50%" style="zoom:67%"></p><p>第四，是博客中给出的 <strong>Test-time Scaling Law</strong>。关键是测试时也能 Scaling！这就否定了一些网友关于 Reflection 式输出的猜测（总所周知，前几天翻车的 Reflection-70B 就是<strong>标注了大量 CoT 数据</strong>，让模型在输出时模仿更多的反思步骤，「内置 CoT」刷爆了排行榜）。<strong>如果采用这种「简单内置 CoT」的方式，是很难自由地控制 Test-time Compute 的！</strong></p><blockquote><p>People have discovered a while ago that prompting the model to “think step by step” boosts performance. But training the model to do this, end to end with trial and error, is far more reliable and — as we’ve seem with games like Go or Dota — can generate extremely impressive results.</p><p>人们早已发现，提示模型"逐步思考"可以提升其表现。但是通过端到端的试错方式来训练模型这样做，会使结果更加可靠，而且——正如我们在围棋或 Dota 等游戏中看到的那样——可以产生极其令人印象深刻的结果。</p></blockquote><p><img src="/img/blog/OpenAI-o1-Series-images/fig2.jpg" srcset="/img/loading.gif" lazyload alt="OpenAI 分别测试了训练和测试时的 Compute 影响" style="zoom:67%"></p><p>最后，是一些其他细节。这里列举出来：</p><ul><li>OpenAI 向用户<strong>隐藏了内在思维过程，</strong>目前网页端显示的是总结后的 CoT 过程；</li><li>o1 的输入 tokens 计算方式与 GPT-4o 相同，<strong>使用相同的分词器</strong>；</li><li>网友测试，模型的思考时间时快时慢，说明其<strong>可以决定何时退出思考</strong>；</li><li>网友测试，模型的思考过程中，经常会有 Hmmm, Wait 这类词出现，并且在<strong>发现错误后立刻纠正</strong>；</li><li>网友测试，o1-mini 能够探索更多的思考链条，相较于 o1-preview（不保真）；</li><li>网友测试，o1 对提示词更敏感，一些传统的 Prompt 策略（如角色扮演、类比举例等）反而会起到副作用，<strong>而简单让其回答效果更好（因为会默认进行思考）</strong>；</li><li>o1 系列的模型在网页端<strong>不支持修改系统提示词</strong>；</li><li>o1 系列的模型目前<strong>不支持图像输入、函数调用、结构化输出</strong>，但是据说之后会有。</li></ul><p><img src="/img/blog/OpenAI-o1-Series-images/fig3.jpg" srcset="/img/loading.gif" lazyload alt="群友的测试结果，笑死，思考真的有用" style="zoom:50%"></p><hr><p>那么，OpenAI o1 背后的技术也就呼之欲出了~</p><ol type="1"><li>新模型是在 GPT-4o 上进行的继续训练，具体的训练策略应该就是流传的 <strong>Self-play RL / Q*</strong>。说人话就是：让模型进行在线探索 / MCTS 采样，探索过程中给予不同路径不同的 Critic / 奖励，从中优化模型。</li><li>新模型在<strong>推理的时候也用了相同的策略去采样和奖励</strong>，所以会慢几倍！例如，并行采样 + 并行 Critic 反馈 + 投票 Summarize 出最终输出，理论上<strong>至少是三倍时间，多倍推理成本</strong>（o1 相比 4o 提高了 6 倍，o1-mini 相比 4o-mini 提高了 20 倍，也很合理，更弱的模型就采样更多次）</li><li>Critic 反馈的过程中，Action Model 和 Critic Model 可能会有多轮交互（Retry），并<strong>最终由 Critic Model 或 Summarize Model 决定是否退出</strong>。因此时间会大于三倍，并且根据问题的复杂度上升！</li></ol><h2 id="相关论文">相关论文</h2><p>附上一些可能的相关论文~ 会持续更新...</p><p><strong>Self-Critic 相关论文：</strong></p><ul><li>标题：LLM Critics Help Catch LLM Bugs<ul><li>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.00215">https://arxiv.org/abs/2407.00215</a></li><li>简介：OpenAI 的 CriticGPT，通过训练“批评者”模型来帮助人类更准确地评估由大型语言模型（LLM）生成的代码。这些批评者模型本身也是通过强化学习从人类反馈中训练出来的 LLM，能够用自然语言突出代码中的问题。研究发现，CriticGPT 在识别代码中自然出现的错误方面，比人类批评者更受青睐，并且在捕获错误方面比人类承包商更有效。</li></ul></li><li>标题：Generative Verifiers: Reward Modeling as Next-Token Prediction<ul><li>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.15240">https://arxiv.org/abs/2408.15240</a><br></li><li>简介：Google 出品，介绍了一种新型的验证器（Verifier），称为生成性验证器（Generative Verifiers，简称 GenRM），它通过将验证问题转化为下一个词（next-token）预测任务来提高大型语言模型（LLMs）的推理性能。这种方法与传统的基于判别式分类的训练不同，它充分利用了预训练 LLMs 的文本生成能力。</li></ul></li></ul><p><strong>MCTS &amp; Self-Improve 相关论文：</strong></p><ul><li>标题：Recursive Introspection: Teaching Language Model Agents How to Self-Improve<ul><li>链接：<a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.18219">http://arxiv.org/abs/2407.18219</a></li><li>简介：提出 RISE 递归自省，目的是提高模型在测试时连续尝试的响应的最终正确率（Test-time self-improve）。为此，将连续响应建模为 MDP，用 BoN 或者强模型的输出构造训练。</li></ul></li><li>标题：Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers<ul><li>链接：<a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.06195">http://arxiv.org/abs/2408.06195</a><br></li><li>简介：提出 rStar，增强 MCTS 的 action space，同时用同一个模型验证生成的每个轨迹，类似 Self-Verify。</li></ul></li><li>标题：Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning<ul><li>链接：<a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.14283">http://arxiv.org/abs/2406.14283</a><br></li><li>简介：学习 Q-value 模型作为预估奖励的启发式函数，指导 LLM 搜索并选择推理步骤。</li></ul></li><li>标题：AlphaMath Almost Zero: process Supervision without process<ul><li>链接：<a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.03553">http://arxiv.org/abs/2405.03553</a><br></li><li>简介：将 Alphago 自我对弈阶段的思路引入 Math，不需要人工标注的解题中间过程，使用 MCTS + 过程奖励估算。</li></ul></li><li>标题：Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning<ul><li>链接：<a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.05808">http://arxiv.org/abs/2402.05808</a></li><li>简介：ICML 上的一篇论文，提出 R^3 训练框架，逆向课程学习，仅使用结果监督的信号来模拟过程监督的效果。</li></ul></li></ul><p><strong>Test-time Scaling Law 相关论文：</strong></p><ul><li>标题：Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters<ul><li>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.03314">https://arxiv.org/abs/2408.03314</a><br></li><li>简介：Google 出品，研究了 LLM 中推理时间计算的 Scaling Law，回答了以下问题：如果允许 LLM 使用固定量的推理时计算量，那么它能在多大程度上提高其在具有挑战性的任务上的性能？</li></ul></li><li>标题：An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models<ul><li>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.00724">https://arxiv.org/abs/2408.00724</a><br></li><li>简介：探讨了在有限计算资源下，如何配置 LLMs 以实现最优的推理性能。实验表明，使用 REBASE 算法的较小语言模型（如 Llemma-7B）在计算资源减半的情况下，能够达到与较大模型（如 Llemma-34B）相当的准确性。</li></ul></li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" class="category-chain-item">论文阅读</a> <span>></span> <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%89%8D%E6%B2%BF%E7%83%AD%E7%82%B9/" class="category-chain-item">前沿热点</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/LLMs/" class="print-no-link">#LLMs</a></div></div><div class="license-box my-3"><div class="license-title"><div>OpenAI o1 系列模型背后的技术猜测</div><div>https://hwcoder.top/OpenAI-o1-Series</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Wei He</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2024年9月13日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i> </span></a><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="NC - 非商业性使用"><i class="iconfont icon-nc"></i> </span></a><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="SA - 相同方式共享"><i class="iconfont icon-sa"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/Awesome-Prompts" title="常用 Prompt 合集"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">常用 Prompt 合集</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/Manual-Coding-3" title="手撕经典算法 #3 Transformer篇"><span class="hidden-mobile">手撕经典算法 #3 Transformer篇</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"jdbBr3BddTiqSCPnXw6sXFv7-gzGzoHsz","appKey":"2bjgwDr2opjVCwhgjDMpk53c","path":"window.location.pathname","placeholder":"说点什么吧( •̀ ω •́ )✧","avatar":"retro","meta":["nick","mail","link"],"requiredFields":["nick"],"pageSize":10,"lang":"zh-CN","highlight":true,"recordIP":true,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t){var e=Fluid.plugins.typing,i=t.getElementById("subtitle");i&&e&&e(i.getAttribute("data-typed-text"))}((window,document))</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-t},CONFIG.toc)),0<o.find(".toc-list-item").length&&o.css("visibility","visible"),Fluid.events.registerRefreshCallback(function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;0<t.find(".toc-list-item").length&&t.css("visibility","visible")}}))})</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>Fluid.plugins.imageCaption()</script><script defer src="/js/leancloud.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>